import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os
import urllib.request
import re
from datetime import datetime, timedelta
import io

# ==========================================
# 0. å…¨åŸŸè¨­å®šï¼šAI é¡§å•æŒ‡ä»¤ (å®Œæ•´ä¿®å¾©ç‰ˆ)
# ==========================================
AI_CONSULTANT_PROMPT = """
# âš ï¸ SYSTEM OVERRIDE: DATA LOADING INSTRUCTION
**To the AI Analysis Model:**
The user has uploaded a **Single-Sheet Excel File**.
1. **ALL DATA** is contained in the **First Sheet** named 'ğŸ“˜_å®Œæ•´åˆ†æå ±å‘Š'.
2. The content is organized as **Vertically Stacked Tables**.
3. The structure is:
   - **[Top Section]**: This Instruction (Prompt).
   - **[Middle Section]**: Q13_Trend Data (Daily Trend).
   - **[Bottom Section]**: Consolidated Data Tables for P7D, PP7D, and P30D (Campaign/AdSet/Ad levels).
4. **ACTION**: Please read the entire sheet. Scan for headers like "Table: ..." to identify different datasets.

---

# Role
ä½ æ˜¯ä¸€ä½æ“æœ‰ 10 å¹´ç¶“é©—çš„è³‡æ·±æˆæ•ˆå»£å‘Šåˆ†æå¸«ã€‚è«‹æ ¹æ“šæœ¬é é¢ä¸­çš„æ‰€æœ‰æ•¸æ“šé€²è¡Œå¸³æˆ¶å¥æª¢ã€‚

# Data Structure & Sorting Logic
- **Q13_Trend**: ä¾æ—¥æœŸæ’åºçš„æ¯æ—¥è¶¨å‹¢ã€‚
- **Consolidated Tables (P7D/PP7D/P30D)**:
    - é€™äº›è¡¨æ ¼é è¨­ **ã€Œä¾èŠ±è²»é‡‘é¡ (Spend) ç”±é«˜åˆ°ä½æ’åã€**ã€‚
    - **åˆ†æé‡é»**: è«‹å„ªå…ˆé—œæ³¨æ’åå‰ 3-5 åçš„ã€Œé«˜èŠ±è²»é …ç›®ã€ï¼Œå®ƒå€‘å°æ•´é«”å¸³æˆ¶å½±éŸ¿æœ€å¤§ã€‚
    - è¡¨æ ¼æœ€å¾Œä¸€åˆ—é€šå¸¸æ˜¯ **ã€Œå…¨å¸³æˆ¶å¹³å‡ (Account Average)ã€**ï¼Œè«‹ä»¥æ­¤ä½œç‚ºåŸºæº–ç·š (Benchmark)ã€‚

# Analysis Requirements

## 1. æ³¢å‹•åµæ¸¬ (Fluctuation Analysis)
- **å…¨ç«™é«”æª¢**: å„ªå…ˆæŸ¥çœ‹ä¸Šæ–¹ `Q13_Trend` è¡¨æ ¼ä¸­çš„ **ã€ŒğŸ† æ•´é«”å¸³æˆ¶ã€** è¶¨å‹¢ç·šï¼Œåˆ¤æ–·æ•´é«” CVR èˆ‡ CPA èµ°å‹¢ã€‚
- **ç´°é …å°æ¯”**: å¾€ä¸‹æ²å‹•ï¼Œæ‰¾åˆ° **P7D (æœ¬é€±)** èˆ‡ **PP7D (ä¸Šé€±)** çš„è¡¨æ ¼é€²è¡Œç’°æ¯”åˆ†æã€‚
- æ‰¾å‡º CPA æš´æ¼²æˆ– CVR é©Ÿé™çš„ã€Œè­¦ç¤ºå€ã€ã€‚

## 2. æ“´é‡æ©Ÿæœƒ (Scaling)
- æ‰¾å‡º **CPA ä½ä¸”ç©©å®š** çš„è¡ŒéŠ·æ´»å‹•/å»£å‘Šçµ„åˆ -> å»ºè­°åŠ ç¢¼ã€‚
- æ‰¾å‡º **High CTR / Low Spend** çš„æ½›åŠ›ç´ æ -> å»ºè­°çµ¦äºˆç¨ç«‹é ç®—ã€‚
- æ‰¾å‡º **High CTR / Low CVR** çš„é …ç›® -> å»ºè­°å„ªåŒ–è½åœ°é ã€‚

## 3. æ­¢æå»ºè­° (Cost Cutting)
- æ‰¾å‡º **é«˜èŠ±è²» but 0 è½‰æ›** çš„é …ç›®ã€‚
- æ‰¾å‡º **CPA éé«˜ä¸” CTR ä½è½** çš„ç„¡æ•ˆå»£å‘Šã€‚

## 4. ç¶œåˆæˆ°è¡“è¡Œå‹•æ¸…å–® (Action Plan)
è«‹åˆ—å‡ºå…·é«”çš„ï¼š
- **ğŸ”´ æ‡‰é—œé–‰**: å…·é«”åˆ—å‡ºè©²é—œé–‰çš„ç´ æ/å—çœ¾åç¨±ã€‚
- **ğŸŸ¢ æ‡‰åŠ å¼·**: å…·é«”åˆ—å‡ºè©²åŠ ç¢¼çš„é …ç›®ã€‚
- **ğŸ’° é ç®—èª¿æ•´**: å…·é«”çš„é ç®—å¢æ¸›å»ºè­°ã€‚
- **ğŸ¨ ç´ æ/ç¶²é å„ªåŒ–**: ä¸‹ä¸€æ­¥è©²åšä»€éº¼åœ–ï¼Ÿè©²æ”¹ä»€éº¼æ–‡æ¡ˆï¼Ÿ

# Output Format
è«‹è¼¸å‡ºå°ˆæ¥­åˆ†æå ±å‘Šï¼Œä¸¦ç¢ºä¿ã€Œæˆ°è¡“è¡Œå‹•æ¸…å–®ã€æ¸…æ™°å¯åŸ·è¡Œã€‚
"""

# ==========================================
# 1. åŸºç¤è¨­å®šèˆ‡å­—å‹è™•ç†
# ==========================================
st.set_page_config(page_title="å»£å‘Šæˆæ•ˆå…¨èƒ½åˆ†æ v4.1", layout="wide")

@st.cache_resource
def get_chinese_font():
    font_path = "NotoSansCJKtc-Regular.otf"
    url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/TraditionalChinese/NotoSansCJKtc-Regular.otf"
    if not os.path.exists(font_path):
        try:
            with st.spinner('æ­£åœ¨ä¸‹è¼‰ä¸­æ–‡å­—å‹ (é¦–æ¬¡åŸ·è¡Œéœ€æ™‚è¼ƒä¹…)...'):
                urllib.request.urlretrieve(url, font_path)
        except:
            return None
    return fm.FontProperties(fname=font_path)

font_prop = get_chinese_font()

# ==========================================
# 2. è³‡æ–™è™•ç†æ ¸å¿ƒå‡½æ•¸
# ==========================================

def clean_ad_name(name):
    return re.sub(r' - è¤‡æœ¬.*$', '', str(name)).strip()

def create_summary_row(df, metric_cols):
    summary_dict = {}
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        summary_dict[col] = df[col].sum()
        
    for metric, (num, denom, is_pct) in metric_cols.items():
        total_num = summary_dict.get(num, 0)
        total_denom = summary_dict.get(denom, 0)
        if total_denom > 0:
            val = (total_num / total_denom)
            if is_pct: val *= 100
            summary_dict[metric] = round(val, 2)
        else:
            summary_dict[metric] = 0

    non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns
    if len(non_numeric_cols) > 0:
        summary_dict[non_numeric_cols[0]] = 'å…¨å¸³æˆ¶å¹³å‡'
        for col in non_numeric_cols[1:]:
            summary_dict[col] = '-'
    return pd.DataFrame([summary_dict])

def calculate_metrics_consolidated(df_group, conv_col):
    # èšåˆ
    df_metrics = df_group.agg({
        'èŠ±è²»é‡‘é¡ (TWD)': 'sum',
        conv_col: 'sum',
        'é€£çµé»æ“Šæ¬¡æ•¸': 'sum',
        'æ›å…‰æ¬¡æ•¸': 'sum'
    }).reset_index()
    
    df_metrics = df_metrics[df_metrics['èŠ±è²»é‡‘é¡ (TWD)'] > 0]
    
    # è¨ˆç®—æŒ‡æ¨™
    df_metrics['CPA'] = df_metrics.apply(lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x[conv_col] if x[conv_col] > 0 else 0, axis=1)
    df_metrics['CTR (%)'] = df_metrics.apply(lambda x: (x['é€£çµé»æ“Šæ¬¡æ•¸'] / x['æ›å…‰æ¬¡æ•¸']) * 100 if x['æ›å…‰æ¬¡æ•¸'] > 0 else 0, axis=1)
    df_metrics['CVR (%)'] = df_metrics.apply(lambda x: (x[conv_col] / x['é€£çµé»æ“Šæ¬¡æ•¸']) * 100 if x['é€£çµé»æ“Šæ¬¡æ•¸'] > 0 else 0, axis=1)
    
    df_metrics = df_metrics.round(2).sort_values(by='èŠ±è²»é‡‘é¡ (TWD)', ascending=False)
    
    # å¹³å‡åˆ—
    metric_config = {
        'CPA': ('èŠ±è²»é‡‘é¡ (TWD)', conv_col, False),
        'CTR (%)': ('é€£çµé»æ“Šæ¬¡æ•¸', 'æ›å…‰æ¬¡æ•¸', True),
        'CVR (%)': (conv_col, 'é€£çµé»æ“Šæ¬¡æ•¸', True)
    }
    summary_row = create_summary_row(df_metrics, metric_config)
    
    if not df_metrics.empty:
        return pd.concat([df_metrics, summary_row], ignore_index=True)
    return df_metrics

def prepare_excel_data(df, period_name_short, conv_col):
    """æº–å‚™ Excel ç”¨çš„æ•¸æ“šå¡Š"""
    df['å»£å‘Šåç¨±_clean'] = df['å»£å‘Šåç¨±'].apply(clean_ad_name)
    cols = [conv_col, 'èŠ±è²»é‡‘é¡ (TWD)', 'é€£çµé»æ“Šæ¬¡æ•¸', 'æ›å…‰æ¬¡æ•¸']
    df[cols] = df[cols].fillna(0)
    
    results = []
    results.append((f'{period_name_short}_Ad_å»£å‘Š', calculate_metrics_consolidated(df.groupby('å»£å‘Šåç¨±_clean'), conv_col)))
    results.append((f'{period_name_short}_AdSet_å»£å‘Šçµ„åˆ', calculate_metrics_consolidated(df.groupby(['è¡ŒéŠ·æ´»å‹•åç¨±', 'å»£å‘Šçµ„åˆåç¨±']), conv_col)))
    results.append((f'{period_name_short}_Campaign_è¡ŒéŠ·æ´»å‹•', calculate_metrics_consolidated(df.groupby('è¡ŒéŠ·æ´»å‹•åç¨±'), conv_col)))
    return results

def get_trend_data_excel(df_p30d, conv_col):
    """Excel ç”¨çš„è¶¨å‹¢æ•¸æ“š (å«è¡ŒéŠ·æ´»å‹•ç´°åˆ†)"""
    trend_df = df_p30d.copy()
    
    camp_daily = trend_df.groupby(['å¤©æ•¸', 'è¡ŒéŠ·æ´»å‹•åç¨±']).agg({
        'èŠ±è²»é‡‘é¡ (TWD)': 'sum', conv_col: 'sum', 'é€£çµé»æ“Šæ¬¡æ•¸': 'sum', 'æ›å…‰æ¬¡æ•¸': 'sum'
    }).reset_index()
    
    acc_daily = trend_df.groupby(['å¤©æ•¸']).agg({
        'èŠ±è²»é‡‘é¡ (TWD)': 'sum', conv_col: 'sum', 'é€£çµé»æ“Šæ¬¡æ•¸': 'sum', 'æ›å…‰æ¬¡æ•¸': 'sum'
    }).reset_index()
    acc_daily['è¡ŒéŠ·æ´»å‹•åç¨±'] = 'ğŸ† æ•´é«”å¸³æˆ¶'
    
    final = pd.concat([acc_daily, camp_daily], ignore_index=True)
    final = final[final['èŠ±è²»é‡‘é¡ (TWD)'] > 0]
    
    final['CPA'] = final.apply(lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x[conv_col] if x[conv_col] > 0 else 0, axis=1)
    final['CVR (%)'] = final.apply(lambda x: (x[conv_col] / x['é€£çµé»æ“Šæ¬¡æ•¸']) * 100 if x['é€£çµé»æ“Šæ¬¡æ•¸'] > 0 else 0, axis=1)
    
    final['å¤©æ•¸'] = final['å¤©æ•¸'].dt.strftime('%Y-%m-%d')
    return final.sort_values(by=['å¤©æ•¸', 'è¡ŒéŠ·æ´»å‹•åç¨±'])

def generate_single_sheet_excel(dfs_list, prompt_text):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        workbook = writer.book
        ws = workbook.add_worksheet('ğŸ“˜_å®Œæ•´åˆ†æå ±å‘Š')
        writer.sheets['ğŸ“˜_å®Œæ•´åˆ†æå ±å‘Š'] = ws
        
        fmt_header = workbook.add_format({'bold': True, 'font_size': 14, 'font_color': '#0068C9'})
        fmt_prompt = workbook.add_format({'text_wrap': True, 'valign': 'top', 'bg_color': '#F0F2F6'})
        fmt_th = workbook.add_format({'bold': True, 'bg_color': '#E6E6E6', 'border': 1})
        
        row = 0
        # å¯«å…¥ Prompt
        ws.merge_range('A1:H1', "ğŸ¤– AI åˆ†æé¡§å•æŒ‡ä»¤", fmt_header)
        row += 1
        # è‡ªå‹•è¨ˆç®— Prompt è¡Œæ•¸
        prompt_lines = prompt_text.count('\n') + 5
        ws.merge_range(row, 0, row + prompt_lines, 10, prompt_text, fmt_prompt)
        row += prompt_lines + 2
        
        ws.write(row, 0, "--- ğŸ“Š DATA SECTION START ---", fmt_header)
        row += 2
        
        for title, df in dfs_list:
            ws.write(row, 0, f"ğŸ“Œ Table: {title}", fmt_header)
            row += 1
            df.to_excel(writer, sheet_name='ğŸ“˜_å®Œæ•´åˆ†æå ±å‘Š', startrow=row, index=False)
            for i, col in enumerate(df.columns):
                ws.write(row, i, col, fmt_th)
            row += len(df) + 4
            
        ws.set_column('A:A', 40)
        ws.set_column('B:Z', 15)
    output.seek(0)
    return output.getvalue()

# ==========================================
# 3. ä¸»ç¨‹å¼ UI é‚è¼¯
# ==========================================
st.title("ğŸ“Š å»£å‘Šæˆæ•ˆå…¨èƒ½åˆ†æå„€è¡¨æ¿ (v4.1 å®Œæ•´æŒ‡ä»¤ç‰ˆ)")
st.caption("æ•´åˆåŠŸèƒ½ï¼šæ¯æ—¥è¶¨å‹¢å¯è¦–åŒ– + è©³ç´°æ•¸æ“šè¡¨æ ¼ + AI å°ˆç”¨å–®é å ±è¡¨åŒ¯å‡º")

uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ CSV å ±è¡¨æª”æ¡ˆ", type=['csv'])

if uploaded_file is not None:
    try:
        # 1. è®€å–èˆ‡æ¬„ä½åµæ¸¬
        df = pd.read_csv(uploaded_file)
        df.columns = df.columns.str.strip()
        all_columns = df.columns.tolist()
        
        # å´é‚Šæ¬„ï¼šè¨­å®šå€
        with st.sidebar:
            st.header("âš™ï¸ åˆ†æè¨­å®š")
            
            # æ™ºæ…§åµæ¸¬è½‰æ›æ¬„ä½
            suggested_idx = 0
            for idx, col in enumerate(all_columns):
                c_low = col.lower()
                if 'æˆæœ¬' in col or 'cost' in c_low: continue
                if ('free' in c_low and 'course' in c_low): suggested_idx = idx; break
                if 'è³¼è²·' in col or 'purchase' in c_low: suggested_idx = idx; break
                if 'è½‰æ›' in col: suggested_idx = idx; break
                if 'æˆæœ' in col: suggested_idx = idx; break
                
            conversion_col = st.selectbox(
                "ğŸ¯ ç›®æ¨™è½‰æ›æ¬„ä½:",
                options=all_columns,
                index=suggested_idx
            )
            
            # å˜—è©¦æ‰¾æ¨™æº–æ¬„ä½
            def find_col(opts, default):
                for opt in opts:
                    for col in all_columns:
                        if opt in col: return col
                return default

            spend_col = find_col(['èŠ±è²»é‡‘é¡ (TWD)', 'èŠ±è²»', 'é‡‘é¡'], 'èŠ±è²»é‡‘é¡ (TWD)')
            clicks_col = find_col(['é€£çµé»æ“Šæ¬¡æ•¸', 'é€£çµé»æ“Š'], 'é€£çµé»æ“Šæ¬¡æ•¸')
            impressions_col = find_col(['æ›å…‰æ¬¡æ•¸', 'æ›å…‰'], 'æ›å…‰æ¬¡æ•¸')
            
            st.info(f"å·²é–å®šï¼š\nğŸ’° èŠ±è²»: {spend_col}\nğŸ–±ï¸ é»æ“Š: {clicks_col}\nğŸ‘€ æ›å…‰: {impressions_col}")

        # 2. è³‡æ–™æ¸…æ´—
        req_cols = [spend_col, clicks_col, impressions_col, conversion_col]
        df[req_cols] = df[req_cols].fillna(0)
        df['å¤©æ•¸'] = pd.to_datetime(df['å¤©æ•¸'])
        
        # æ¨™æº–åŒ–æ¬„ä½åç¨± (æ–¹ä¾¿å¾ŒçºŒè™•ç†ï¼Œé™¤äº† conversion_col)
        df_std = df.rename(columns={
            spend_col: 'èŠ±è²»é‡‘é¡ (TWD)',
            clicks_col: 'é€£çµé»æ“Šæ¬¡æ•¸',
            impressions_col: 'æ›å…‰æ¬¡æ•¸'
        })
        
        # æ—¥æœŸå€é–“è¨­å®š
        max_date = df_std['å¤©æ•¸'].max().normalize()
        today = max_date + timedelta(days=1)
        p7d_start = today - timedelta(days=7)
        p30d_start = today - timedelta(days=30)
        
        df_p7d = df_std[(df_std['å¤©æ•¸'] >= p7d_start) & (df_std['å¤©æ•¸'] < today)].copy()
        df_p30d = df_std[(df_std['å¤©æ•¸'] >= p30d_start) & (df_std['å¤©æ•¸'] < today)].copy()
        
        # --- åˆ†é å…§å®¹ ---
        tab1, tab2 = st.tabs(["ğŸ“ˆ è¦–è¦ºåŒ–å„€è¡¨æ¿ (Dashboard)", "ğŸ“‘ è©³ç´°æ•¸æ“šåˆ—è¡¨ (Details)"])
        
        # === TAB 1: è¦–è¦ºåŒ–åœ–è¡¨ ===
        with tab1:
            # 1. æ•¸æ“šæ‘˜è¦
            total_spend = df_p30d['èŠ±è²»é‡‘é¡ (TWD)'].sum()
            total_conv = df_p30d[conversion_col].sum()
            cpa_30d = total_spend / total_conv if total_conv > 0 else 0
            
            c1, c2, c3 = st.columns(3)
            c1.metric("è¿‘30æ—¥ç¸½èŠ±è²»", f"${total_spend:,.0f}")
            c2.metric(f"è¿‘30æ—¥ç¸½è½‰æ› ({conversion_col})", f"{total_conv:,.0f}")
            c3.metric("è¿‘30æ—¥å¹³å‡ CPA", f"${cpa_30d:,.0f}")
            
            st.divider()
            
            # 2. æ¯æ—¥è¶¨å‹¢åœ– (ä½¿ç”¨ Matplotlib)
            daily = df_p30d.groupby('å¤©æ•¸')[['èŠ±è²»é‡‘é¡ (TWD)', conversion_col, 'é€£çµé»æ“Šæ¬¡æ•¸', 'æ›å…‰æ¬¡æ•¸']].sum().reset_index()
            
            # è¨ˆç®—æ¯æ—¥æŒ‡æ¨™
            daily['CPM'] = daily.apply(lambda x: x['èŠ±è²»é‡‘é¡ (TWD)']/x['æ›å…‰æ¬¡æ•¸']*1000 if x['æ›å…‰æ¬¡æ•¸']>0 else 0, axis=1)
            daily['CTR'] = daily.apply(lambda x: x['é€£çµé»æ“Šæ¬¡æ•¸']/x['æ›å…‰æ¬¡æ•¸'] if x['æ›å…‰æ¬¡æ•¸']>0 else 0, axis=1)
            daily['CVR'] = daily.apply(lambda x: x[conversion_col]/x['é€£çµé»æ“Šæ¬¡æ•¸'] if x['é€£çµé»æ“Šæ¬¡æ•¸']>0 else 0, axis=1)
            
            plot_data = daily[daily['èŠ±è²»é‡‘é¡ (TWD)'] > 0].copy()
            plot_data['æ—¥æœŸstr'] = plot_data['å¤©æ•¸'].dt.strftime('%m-%d')
            
            metrics_cfg = [
                ('èŠ±è²»é‡‘é¡ (TWD)', 'æ¯æ—¥èŠ±è²» (Spend)', 'red'),
                (conversion_col, f'æ¯æ—¥è½‰æ› ({conversion_col})', 'brown'),
                ('CVR', 'è½‰æ›ç‡ (CVR)', 'magenta'),
                ('CPA', 'è½‰æ›æˆæœ¬ (CPA)', 'purple', lambda x: x['èŠ±è²»é‡‘é¡ (TWD)']/x[conversion_col] if x[conversion_col]>0 else 0)
            ]
            
            # ç¹ªåœ–
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            axes = axes.flatten()
            
            for i, cfg in enumerate(metrics_cfg):
                col_name, title, color = cfg[0], cfg[1], cfg[2]
                ax = axes[i]
                
                # ç‰¹åˆ¥è™•ç† CPA è¨ˆç®—
                if len(cfg) > 3: # è‡ªå®šç¾©è¨ˆç®—å‡½æ•¸
                    y_vals = plot_data.apply(cfg[3], axis=1)
                    label_fmt = "{:.0f}"
                else:
                    y_vals = plot_data[col_name]
                    label_fmt = "{:.1%}" if col_name in ['CTR', 'CVR'] else "{:.0f}"
                
                ax.plot(plot_data['æ—¥æœŸstr'], y_vals, marker='o', color=color, linewidth=2)
                
                if font_prop:
                    ax.set_title(title, fontproperties=font_prop, fontsize=14)
                    ax.set_xlabel('æ—¥æœŸ', fontproperties=font_prop)
                    for label in ax.get_xticklabels() + ax.get_yticklabels():
                        label.set_fontproperties(font_prop)
                else:
                    ax.set_title(title) # Fallback
                
                ax.grid(True, linestyle='--', alpha=0.7)
                
                # æ¨™ç±¤
                for x, y in zip(plot_data['æ—¥æœŸstr'], y_vals):
                    ax.annotate(label_fmt.format(y), (x, y), textcoords="offset points", xytext=(0,8), ha='center', fontsize=9)
            
            plt.tight_layout()
            st.pyplot(fig)

        # === TAB 2: è©³ç´°æ•¸æ“š ===
        with tab2:
            st.markdown("#### ğŸ“Š å„ç¶­åº¦æ•¸æ“šç¸½è¦½")
            t_p7, t_p30 = st.tabs(["P7D (è¿‘7å¤©)", "P30D (è¿‘30å¤©)"])
            
            with t_p7:
                res_p7 = prepare_excel_data(df_p7d, 'P7D', conversion_col)
                st.dataframe(res_p7[2][1], use_container_width=True) # è¡ŒéŠ·æ´»å‹•
                with st.expander("æŸ¥çœ‹å»£å‘Šçµ„åˆèˆ‡å»£å‘Šç´°ç¯€"):
                    st.write("å»£å‘Šçµ„åˆ (AdSet):")
                    st.dataframe(res_p7[1][1], use_container_width=True)
                    st.write("å»£å‘Š (Ad):")
                    st.dataframe(res_p7[0][1], use_container_width=True)
            
            with t_p30:
                res_p30 = prepare_excel_data(df_p30d, 'P30D', conversion_col)
                st.dataframe(res_p30[2][1], use_container_width=True)

        # === å´é‚Šæ¬„ä¸‹è¼‰å€ (æœ€å¾ŒåŸ·è¡Œ) ===
        with st.sidebar:
            st.divider()
            st.header("ğŸ“¥ å ±å‘Šä¸‹è¼‰")
            
            # æº–å‚™ Excel æ•¸æ“š
            excel_stack = []
            # 1. Trend
            excel_stack.append(('Q13_Trend', get_trend_data_excel(df_p30d, conversion_col)))
            # 2. Periods
            excel_stack.extend(prepare_excel_data(df_p7d, 'P7D', conversion_col))
            excel_stack.extend(prepare_excel_data(df_p30d, 'P30D', conversion_col))
            
            excel_bytes = generate_single_sheet_excel(excel_stack, AI_CONSULTANT_PROMPT)
            
            st.download_button(
                label="ä¸‹è¼‰ AI å°ˆç”¨å–®é å ±è¡¨ (.xlsx)",
                data=excel_bytes,
                file_name=f"Full_Report_{conversion_col}_{max_date.strftime('%Y%m%d')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                help="åŒ…å«å®Œæ•´çš„ System Promptã€æ¯æ—¥è¶¨å‹¢èˆ‡å„å±¤ç´šæ•¸æ“šï¼Œå¯ç›´æ¥ä¸Šå‚³çµ¦ AI é€²è¡Œåˆ†æã€‚"
            )

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
        st.info("è«‹ç¢ºèª CSV æª”æ¡ˆæ ¼å¼æ­£ç¢ºï¼Œä¸”åŒ…å«èŠ±è²»ã€é»æ“Šèˆ‡è½‰æ›æ•¸æ“šã€‚")
