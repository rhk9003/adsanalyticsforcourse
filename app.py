import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os
import urllib.request
import re
from datetime import datetime, timedelta
import io
import requests  # ç”¨æ–¼ REST API å…¼å®¹æ¨¡å¼
import json      # ç”¨æ–¼è™•ç† API å›å‚³æ ¼å¼

# --- æ ¸å¿ƒä¿®æ­£ï¼šå®‰å…¨å¼•å…¥å¥—ä»¶ä»¥é˜²æ­¢ App é–ƒé€€ ---
try:
    import google.generativeai as genai
    HAS_GENAI = True
except ModuleNotFoundError:
    HAS_GENAI = False

# æª¢æŸ¥ xlsxwriter æ˜¯å¦å­˜åœ¨ (Excel åŒ¯å‡ºéœ€è¦)
try:
    import xlsxwriter
    HAS_XLSXWRITER = True
except ModuleNotFoundError:
    HAS_XLSXWRITER = False
# -------------------------------------------

# ==========================================
# ==========================================
# 0. å…¨åŸŸè¨­å®šï¼šAI é¡§å•æŒ‡ä»¤ï¼ˆv4.0 æ·±åº¦ç´°ç¯€+é«˜éšé‚è¼¯å®Œå…¨é«”ï¼‰
# ==========================================
AI_CONSULTANT_PROMPT = """
# Role
ä½ æ˜¯ä¸€ä½è³‡æ·±æˆæ•ˆå»£å‘Šåˆ†æå¸«ï¼ŒåŒæ™‚ä¹Ÿæ˜¯ã€Œåª’é«”æ¡è²·æ±ºç­–é¡§å•ã€ã€‚
ä½ çš„åˆ†æé¢¨æ ¼å¿…é ˆå…¼å…·**ã€Œæ•¸æ“šé¡†ç²’åº¦çš„ç´°è†©æ‹†è§£ã€**èˆ‡**ã€Œé ç®—é…ç½®çš„æˆ°ç•¥åˆ¤æ–·ã€**ã€‚
è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œèªæ°£å°ˆæ¥­ç²¾æº–ã€æ¢åˆ—æ¸…æ¥šã€ç›´æ¥çµ¦å¯åŸ·è¡Œæ±ºç­–ã€‚

# è³‡æ–™ä¾†æºèªªæ˜
ç³»çµ±æœƒæä¾›å¤šå€‹è¡¨æ ¼ï¼ˆDaily Alerts, Weekly Trends, P7D Campaign/AdSet/Ad, 30D Trend, CPM Changeï¼‰ã€‚
è«‹ç¶œåˆé€™äº›æ•¸æ“šé€²è¡Œåˆ†æã€‚

---

# åˆ†æä»»å‹™è¦æ±‚ï¼ˆè«‹å‹™å¿…ä¾åºå®Œæˆï¼Œä¸å¯çœç•¥ç´°ç¯€ï¼‰

## 1. å¸³æˆ¶æ•´é«”å¿«é€Ÿç¸½çµ & é¢¨éšªé è­¦
- **æ•´é«”ç‹€æ…‹**ï¼šæè¿°å¸³æˆ¶ç›®å‰æ˜¯ã€Œåç©©å®š / è¼•å¾®æƒ¡åŒ– / æ˜é¡¯æƒ¡åŒ– / æœ‰æˆé•·ç©ºé–“ã€ã€‚
- **æ•¸æ“šæ¦‚è¦½**ï¼šè¿‘ 7 æ—¥æ•´é«” CPA èˆ‡è½‰æ›é‡çš„å¤§è‡´æ°´ä½ã€‚
- **ã€é—œéµåµæ¸¬ã€‘**ï¼šè«‹ç›´æ¥é»å‡ºå¸³æˆ¶ä¸­æ˜¯å¦å­˜åœ¨**ã€Œé ç®—å¸è¡€é¬¼ã€**ï¼ˆé«˜èŠ±è²»ã€é«˜ CTR ä½†ä½ CVR çš„ç´ æï¼‰æˆ–**ã€Œæ–°èˆŠç´ æé ç®—æ’æ“ ã€**ç¾è±¡ï¼Ÿé€™æ˜¯å¦ç‚ºç•¶å‰æˆæ•ˆå—é˜»çš„ä¸»å› ï¼Ÿ
- è‹¥æ¨£æœ¬æ•¸åä½ï¼Œè«‹æ¨™è¨»ã€Œæ¨£æœ¬ä¸è¶³é¢¨éšªã€ã€‚

---

## 2. ğŸš¨ æ˜¨æ—¥æ•‘ç«æ¸…å–® (Daily Alerts)
- åƒ…é‡å° **Daily Alerts Table** ä¸­æœ‰ç•°å¸¸çš„æ´»å‹•ã€‚
- æ ¼å¼ï¼š
  - ã€å±¤ç´šï¼šè¡ŒéŠ·æ´»å‹•ã€‘ã€ˆåç¨±ã€‰
    - å•é¡Œä¾†æºï¼šDaily Alertï¼ˆCPA æš´æ¼² / CTR é©Ÿé™ / é«˜èŠ±è²» 0 è½‰æ›ï¼‰
    - é—œéµæ•¸å­—ï¼šæ˜¨æ—¥ vs å‡å€¼å°æ¯”
    - **æ€¥æ•‘æŒ‡ä»¤**ï¼šæš«åœ / é™é ç®— / æª¢æŸ¥è¨­å®šï¼ˆè«‹çµ¦å‡ºæ˜ç¢ºå‹•ä½œï¼‰

---

## 3. ğŸ“‰ é€±ç’°æ¯”è¡°é€€è¨ºæ–· (Weekly Trends)
- é‡å° **Weekly Trends Table** ä¸­ã€Œæ˜é¡¯æƒ¡åŒ–ã€çš„æ´»å‹•ï¼Œè«‹ä¾æ“šæ•¸æ“šç‰¹å¾µåˆ†é¡ï¼ˆå¯è¤‡é¸ï¼‰ï¼š
  1. **ã€Œæ“´é‡æ•ˆç‡å·®ã€**ï¼šèŠ±è²»å¤§å¹…å¢åŠ ï¼ŒCPA åŒæ­¥è®Šå·®ï¼ˆé‚Šéš›æ•ˆç›Šéæ¸›ï¼‰ã€‚
  2. **ã€Œç´ æç–²ä¹ / CTR è¡°é€€ã€**ï¼šCTR æ˜é¡¯ä¸‹é™ï¼Œå°è‡´ CPC è®Šè²´ã€‚
  3. **ã€Œè½‰æ›æ•ˆç‡ä¸‹é™ã€**ï¼šCTR æŒå¹³ï¼Œä½† CVR ä¸‹é™ï¼ˆè½åœ°é æˆ–å—çœ¾æ„åœ–å•é¡Œï¼‰ã€‚
- æ¯å€‹æƒ¡åŒ–æ´»å‹•è«‹çµ¦å‡ºå…·é«”å»ºè­°ï¼ˆæ¸›ç¢¼ / é‡æ§‹ / æ›ç´ æï¼‰ã€‚

---

## 3.5 ğŸ’° CPM è®ŠåŒ–èˆ‡æˆæœ¬çµæ§‹é€£å‹•ï¼ˆæ ¸å¿ƒæ´å¯Ÿï¼‰
- çµåˆ **CPM è®ŠåŒ–è¡¨** èˆ‡ **P7D/30D æ•¸æ“š**ï¼Œåˆ†æç«¶åƒ¹ç’°å¢ƒå° CPA çš„å½±éŸ¿ã€‚è«‹ä¾ç…§ä»¥ä¸‹æƒ…å¢ƒé‚è¼¯é€²è¡Œæ¨è«–ï¼š

  1. **CPM ä¸Šå‡ + CPA ä¹Ÿä¸Šå‡**ï¼š
     - è¨ºæ–·ï¼šç«¶åƒ¹è®Šè²´ä¸”è½‰åŒ–æœªè·Ÿä¸Šï¼Œæˆæœ¬çµæ§‹æƒ¡åŒ–ã€‚å»ºè­°æª¢æŸ¥æ˜¯å¦å—çœ¾éçª„æˆ–ç«¶çˆ­åŠ åŠ‡ã€‚
  2. **CPM ä¸Šå‡ + CPA æŒå¹³/ä¸‹é™**ï¼š
     - è¨ºæ–·ï¼š**é«˜å“è³ªæµé‡**ã€‚é›–ç„¶è²´ä½†å—çœ¾ç²¾æº–ï¼ˆCVR é«˜ï¼‰ï¼Œæ˜¯å€¼å¾—ä¿è­·çš„é»ƒé‡‘å€å¡Šã€‚
  3. **CPM ä¸‹é™ + CPA æ²’æ”¹å–„/è®Šå·®**ï¼š
     - è¨ºæ–·ï¼š**åŠ£è³ªæµé‡é™·é˜±**ã€‚è²·åˆ°äº†ä¾¿å®œæ›å…‰ï¼Œä½†å—çœ¾ä¸è²·å–®ï¼ˆCVR ä½ï¼‰ã€‚å»ºè­°æ’é™¤ç‰¹å®šç‰ˆä½æˆ–ç·Šç¸®å—çœ¾ã€‚
  4. **CPM ä¸‹é™ + CPA æ”¹å–„**ï¼š
     - è¨ºæ–·ï¼šå¸‚å ´ç´…åˆ©æˆ–ç´ æä¸­äº†ï¼Œæ‡‰è€ƒæ…®æ“´é‡ã€‚

---

## 4. ğŸ©¸ æ·±åº¦è¨ºæ–·ï¼šé ç®—æ•ˆç‡èˆ‡å…ƒå…‡å®šä½ (AdSet & Ad Level)
**é€™æ˜¯æœ€é‡è¦çš„æ®µè½ã€‚è«‹åˆ©ç”¨ P7D AdSet/Ad è¡¨æ ¼ï¼ŒåŸ·è¡Œã€Œå¾®è§€åµæ¸¬ã€ï¼š**

1.  **åµæ¸¬ã€Œé ç®—å¸è¡€é¬¼ã€(Vampire Creatives)**ï¼š
    - æ‰¾å‡ºèŠ±è²»æ’åå‰ 20% çš„ç´ æä¸­ï¼Œæ˜¯å¦æœ‰ **ã€ŒCTR é«˜ (å¸ç›) ä½† CVR é¡¯è‘—ä½æ–¼å¹³å‡ã€** çš„å»£å‘Šï¼Ÿ
    - **è¨ºæ–·**ï¼šå®ƒé€ æˆäº†ã€Œé«˜é»æ“Šå‡è±¡ã€ï¼Œé¨™å–äº†ç³»çµ±é ç®—ã€‚**å»ºè­°å‹•ä½œï¼šç«‹å³æš«åœã€‚**

2.  **åµæ¸¬ã€Œç³»çµ±åé£Ÿç—‡ã€(System Bias / Cannibalization)**ï¼š
    - æª¢æŸ¥åŒä¸€ AdSet å…§ï¼Œæ˜¯å¦æœ‰ **ã€Œæ–°ç´ æ (å¦‚ 202512xx)ã€CPA å„ªæ–¼ã€ŒèˆŠç´ æã€ï¼Œä½†èŠ±è²»å»é ä½æ–¼èˆŠç´ æ**ï¼Ÿ
    - **è¨ºæ–·**ï¼šèˆŠç´ ææ†‘è—‰æ­·å²æ•¸æ“šéœ¸ä½”é ç®—ï¼Œå°è‡´æ–°ç´ æç„¡æ³•ç™¼æ®ã€‚**å»ºè­°å‹•ä½œï¼šæš«åœåŒçµ„å…§çš„èˆŠç´ æï¼Œå¼·è¿«é ç®—æµå‘æ–°ç´ æã€‚**

3.  **One Bad Apple (å®³ç¾¤ä¹‹é¦¬) ç†è«–**ï¼š
    - ç•¶æŸå€‹ AdSet CPA éé«˜æ™‚ï¼Œæª¢æŸ¥æ˜¯å¦ **ã€Œåªæœ‰ä¸€æ”¯çˆ›å»£å‘Šåœ¨æ‹–ç´¯ã€**ï¼Ÿ
    - **è¨ºæ–·**ï¼šè‹¥æ˜¯ï¼Œ**å»ºè­°ã€Œé—œé–‰è©²å»£å‘Šã€è€Œéã€Œé—œé–‰æ•´å€‹ AdSetã€**ï¼›è‹¥å…¨é«”å»£å‘Šéƒ½å·®ï¼Œæ‰å»ºè­°é—œé–‰ AdSetã€‚

---

## 5. ğŸ“ˆ æ“´é‡èˆ‡åŠ ç¢¼æ©Ÿæœƒ (Scaling)
- æ‰¾å‡ºå…©é¡ç›®æ¨™ï¼š
  1. **ã€Œå¯åŠ ç¢¼æ½›åŠ›è‚¡ã€**ï¼šCPA ä½æ–¼å¸³æˆ¶å¹³å‡ï¼Œä¸”é ç®—ä½”æ¯”å°šä½ï¼ˆé€šå¸¸æ˜¯è¢«åŸ‹æ²’çš„æ–°ç´ ææˆ–æ–°å—çœ¾ï¼‰ã€‚
  2. **ã€Œç©©å®šåŸºæœ¬ç›¤ã€**ï¼šCPA ç©©å®šã€é‡é«”å¤§çš„èˆŠæ´»å‹•ã€‚
- å»ºè­°ï¼šæ˜ç¢ºæŒ‡å‡ºå“ªå€‹ AdSet/å»£å‘Š å€¼å¾—åŠ ç¢¼ï¼Œä»¥åŠåŠ ç¢¼çš„æ–¹å¼ï¼ˆç›´æ¥åŠ é ç®— / ç¨ç«‹å‡ºä¾†é–‹æ–°æ´»å‹•ï¼‰ã€‚

---

## 6. âœ… å„ªå…ˆç´šå¾…è¾¦æ¸…å–® (Action Plan)
è«‹å°‡æ‰€æœ‰åˆ†ææ”¶æ–‚ç‚ºä¸‰é¡å…·é«”æŒ‡ä»¤ï¼Œä¸¦**è¨»æ˜åˆ¤æ–·ä¾æ“š**ï¼š

1.  **Priority Aï¼šæ­¢è¡€èˆ‡æ¸…å‰µï¼ˆç«‹å³åŸ·è¡Œï¼‰**
    - é‡å°ã€Œé ç®—å¸è¡€é¬¼ã€ã€ã€Œé«˜èŠ±è²» 0 è½‰æ›ã€èˆ‡ã€ŒCPA åš´é‡è¶…æ¨™ã€é …ç›®çš„è™•æ±ºæŒ‡ä»¤ã€‚
    - **æŒ‡ä»¤æ ¼å¼**ï¼š`[æš«åœ]` å»£å‘Š Xï¼ˆä¾æ“šï¼šå¸è¡€é¬¼ç´ æï¼Œé«˜é»æ“Šä½è½‰æ›ï¼‰

2.  **Priority Bï¼šå°æµèˆ‡å„ªåŒ–ï¼ˆè³‡æºé‡åˆ†é…ï¼‰**
    - é‡å°ã€Œè³‡æºéŒ¯ç½®ã€èˆ‡ã€Œç³»çµ±åé£Ÿã€çš„ä¿®æ­£ã€‚
    - **æŒ‡ä»¤æ ¼å¼**ï¼š`[æš«åœ]` AdSet Y ä¸­çš„èˆŠç´ æ Aï¼Œ`[ä¿ç•™]` æ–°ç´ æ Bï¼ˆä¾æ“šï¼šCPA B < Aï¼Œå¼·è¿«å°æµæ¸¬è©¦æ–°ç´ æï¼‰

3.  **Priority Cï¼šä¿è­·åŸºæœ¬ç›¤ï¼ˆè«‹å‹¿æ›´å‹•ï¼‰**
    - é»åé‚£äº›ã€Œé›–ç„¶èˆŠä½†å¾ˆç©©ã€çš„é»ƒé‡‘ç´ æ/å—çœ¾ã€‚
    - **æŒ‡ä»¤æ ¼å¼**ï¼š`[ç¶­æŒ]` AdSet Zï¼ˆä¾æ“šï¼šç©©å®šç²åˆ©ä¾†æºï¼Œå‹¿å› æ“´é‡æ¸¬è©¦è€Œå¹²æ“¾ï¼‰

---


## 7. ğŸ§ª æ–°é …ç›®å¸¶å‹•åˆ¤æ–·ï¼ˆå¿…å¡«ï¼‰
è«‹æ ¹æ“šç³»çµ±æä¾›çš„ã€ŒNew Creatives Summaryã€èˆ‡ã€ŒNew AdSets Summaryã€å›ç­”å…©é¡Œï¼Œå¿…é ˆå¼•ç”¨æ•¸å­—ï¼š

1) æ–°ç´ ææ˜¯å¦æœ‰å¸¶å‹•æ•´é«”æˆé•·ï¼Ÿ
- çµè«–ï¼šæœ‰ / æ²’æœ‰ / ä¸ç¢ºå®šï¼ˆè³‡æ–™ä¸è¶³ï¼‰
- ä¾æ“šï¼šæ–°ç´ æçš„ã€Œè½‰æ›å æ¯”(%)ã€èŠ±è²»å æ¯”(%)ã€CPA vs å…¨å¸³æˆ¶ P7D CPAã€ä¸¦å¼•ç”¨æ•¸å­—
- å‹•ä½œï¼šåŠ ç¢¼ / ä¿ç•™è§€å¯Ÿ / æ·˜æ±° / æ‹†åˆ†ç¨ç«‹

2) æ–°å»£å‘Šçµ„åˆæ˜¯å¦æœ‰å¸¶å‹•æˆé•·ï¼Ÿ
- çµè«–ï¼šæœ‰ / æ²’æœ‰ / ä¸ç¢ºå®š
- ä¾æ“šï¼šPP7Dâ†’P7D èŠ±è²»è®ŠåŒ–ï¼ˆæ–°çµ„åˆåˆ¤å®šï¼‰ã€è½‰æ›å æ¯”(%)ã€CPA è¡¨ç¾ï¼ˆå¼•ç”¨æ•¸å­—ï¼‰
- å‹•ä½œï¼šæ“´é‡ / æ‹†åˆ†ç¨ç«‹ / åœæ­¢æ¸¬è©¦

---

# å›è¦†æ ¼å¼è¦æ±‚
- å¿…é ˆä½¿ç”¨æ¨™é¡Œèˆ‡æ¢åˆ—æ˜ç¢ºåˆ†æ®µã€‚
- æ¯ä¸€é …å»ºè­°éƒ½å¿…é ˆæœ‰**æ•¸æ“šæ”¯æŒ**ï¼ˆä¾‹å¦‚å¼•ç”¨ CPA / CTR / CVR æ•¸å€¼ï¼‰ã€‚
- åœ¨æåˆ°çš„æˆæœ¬æ™‚ï¼Œè«‹æ˜ç¢ºå€åˆ†æ˜¯ CPA (è½‰æ›æˆæœ¬) é‚„æ˜¯ CPM (æ›å…‰æˆæœ¬)ã€‚
"""

# ==========================================
# 1. åŸºç¤è¨­å®šèˆ‡å­—å‹è™•ç†
# ==========================================
st.set_page_config(page_title="å»£å‘Šæˆæ•ˆå…¨èƒ½åˆ†æ v6.4 (Dashboard + Instant DL)", layout="wide")

@st.cache_resource
def get_chinese_font():
    font_path = "NotoSansCJKtc-Regular.otf"
    url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/TraditionalChinese/NotoSansCJKtc-Regular.otf"
    if not os.path.exists(font_path):
        try:
            with st.spinner('æ­£åœ¨ä¸‹è¼‰ä¸­æ–‡å­—å‹ (é¦–æ¬¡åŸ·è¡Œéœ€æ™‚è¼ƒä¹…)...'):
                urllib.request.urlretrieve(url, font_path)
        except Exception:
            return None
    return fm.FontProperties(fname=font_path)

font_prop = get_chinese_font()

# ==========================================
# 2. æ ¸å¿ƒè¨ˆç®—é‚è¼¯
# ==========================================

def clean_ad_name(name):
    return re.sub(r' - è¤‡æœ¬.*$', '', str(name)).strip()


# --- æ–°ç´ æ/æ–°çµ„åˆåˆ¤å®šï¼ˆä½ tokenï¼šç¨‹å¼å…ˆèšåˆï¼ŒAI åªåˆ¤è®€ï¼‰ ---
DATE_RE = re.compile(r'(20\d{2})(0[1-9]|1[0-2])(0[1-9]|[12]\d|3[01])')  # YYYYMMDD

def extract_yyyymmdd(s: str):
    """å¾å­—ä¸²ä¸­æŠ“å‡ºç¬¬ä¸€å€‹ YYYYMMDDï¼Œå›å‚³ date æˆ– None"""
    m = DATE_RE.search(str(s))
    if not m:
        return None
    try:
        return datetime.strptime(m.group(0), "%Y%m%d").date()
    except Exception:
        return None

def is_recent_date(d, anchor_date, days=14):
    """ä»¥ anchor_dateï¼ˆè³‡æ–™ max_dateï¼‰ç‚ºåŸºæº–ï¼Œåˆ¤æ–· d æ˜¯å¦åœ¨æœ€è¿‘ N å¤©å…§"""
    if not d:
        return False
    if isinstance(anchor_date, pd.Timestamp):
        anchor_date = anchor_date.date()
    return (anchor_date - d).days >= 0 and (anchor_date - d).days <= days

def build_new_creatives_summary(df_p7d, conv_col, anchor_date, recent_days=14, top_n=15, min_spend=300):
    """æ–°ç´ æï¼ˆå»£å‘Šï¼‰æ‘˜è¦ï¼šä¾åç¨±ä¸­çš„ YYYYMMDD åˆ¤å®šã€Œè¿‘æœŸæ–°ç´ æã€"""
    if df_p7d is None or df_p7d.empty:
        return pd.DataFrame()

    tmp = df_p7d.copy()
    tmp['å»£å‘Šåç¨±_clean'] = tmp['å»£å‘Šåç¨±'].apply(clean_ad_name)
    tmp['creative_date'] = tmp['å»£å‘Šåç¨±'].apply(extract_yyyymmdd)
    tmp['is_new_creative'] = tmp['creative_date'].apply(lambda d: is_recent_date(d, anchor_date, days=recent_days))

    agg = tmp.groupby(['å»£å‘Šåç¨±_clean', 'is_new_creative'], as_index=False).agg({
        'èŠ±è²»é‡‘é¡ (TWD)': 'sum',
        conv_col: 'sum',
        'é€£çµé»æ“Šæ¬¡æ•¸': 'sum',
        'æ›å…‰æ¬¡æ•¸': 'sum'
    })

    agg['CPA (TWD)'] = agg.apply(lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x[conv_col] if x[conv_col] > 0 else 0, axis=1)
    agg['CTR (%)'] = agg.apply(lambda x: (x['é€£çµé»æ“Šæ¬¡æ•¸'] / x['æ›å…‰æ¬¡æ•¸']) * 100 if x['æ›å…‰æ¬¡æ•¸'] > 0 else 0, axis=1)
    agg['CPC (TWD)'] = agg.apply(lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x['é€£çµé»æ“Šæ¬¡æ•¸'] if x['é€£çµé»æ“Šæ¬¡æ•¸'] > 0 else 0, axis=1)

    total_spend = agg['èŠ±è²»é‡‘é¡ (TWD)'].sum()
    total_conv = agg[conv_col].sum()
    agg['èŠ±è²»å æ¯”(%)'] = agg['èŠ±è²»é‡‘é¡ (TWD)'].apply(lambda v: (v / total_spend * 100) if total_spend > 0 else 0)
    agg['è½‰æ›å æ¯”(%)'] = agg[conv_col].apply(lambda v: (v / total_conv * 100) if total_conv > 0 else 0)

    agg = agg[agg['èŠ±è²»é‡‘é¡ (TWD)'] >= min_spend].copy()
    agg = agg.sort_values(['is_new_creative', 'èŠ±è²»é‡‘é¡ (TWD)'], ascending=[False, False]).head(top_n)

    return agg.round(2)

def build_new_adsets_summary(df_p7d, df_pp7d, conv_col, top_n=15, min_spend_p7=500, old_spend_threshold=200):
    """æ–°å»£å‘Šçµ„åˆåˆ¤å®šï¼šPP7D èŠ±è²»å¾ˆä½ä½† P7D æœ‰æ˜é¡¯èŠ±è²»"""
    if df_p7d is None or df_p7d.empty:
        return pd.DataFrame()

    def agg_adset(df):
        if df is None or df.empty:
            return pd.DataFrame(columns=['è¡ŒéŠ·æ´»å‹•åç¨±', 'å»£å‘Šçµ„åˆåç¨±', 'èŠ±è²»é‡‘é¡ (TWD)', 'è½‰æ›', 'é€£çµé»æ“Šæ¬¡æ•¸', 'æ›å…‰æ¬¡æ•¸'])
        tmp = df.groupby(['è¡ŒéŠ·æ´»å‹•åç¨±', 'å»£å‘Šçµ„åˆåç¨±'], as_index=False).agg({
            'èŠ±è²»é‡‘é¡ (TWD)': 'sum',
            conv_col: 'sum',
            'é€£çµé»æ“Šæ¬¡æ•¸': 'sum',
            'æ›å…‰æ¬¡æ•¸': 'sum'
        })
        tmp = tmp.rename(columns={conv_col: 'è½‰æ›'})
        return tmp

    p7 = agg_adset(df_p7d)
    pp7 = agg_adset(df_pp7d)[['è¡ŒéŠ·æ´»å‹•åç¨±', 'å»£å‘Šçµ„åˆåç¨±', 'èŠ±è²»é‡‘é¡ (TWD)']].rename(columns={'èŠ±è²»é‡‘é¡ (TWD)': 'èŠ±è²»é‡‘é¡_PP7D'})

    merged = p7.merge(pp7, on=['è¡ŒéŠ·æ´»å‹•åç¨±', 'å»£å‘Šçµ„åˆåç¨±'], how='left')
    merged['èŠ±è²»é‡‘é¡_PP7D'] = merged['èŠ±è²»é‡‘é¡_PP7D'].fillna(0)

    merged['is_new_adset'] = (merged['èŠ±è²»é‡‘é¡_PP7D'] < old_spend_threshold) & (merged['èŠ±è²»é‡‘é¡ (TWD)'] >= min_spend_p7)

    merged['CPA (TWD)'] = merged.apply(lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x['è½‰æ›'] if x['è½‰æ›'] > 0 else 0, axis=1)
    merged['CTR (%)'] = merged.apply(lambda x: (x['é€£çµé»æ“Šæ¬¡æ•¸'] / x['æ›å…‰æ¬¡æ•¸']) * 100 if x['æ›å…‰æ¬¡æ•¸'] > 0 else 0, axis=1)
    merged['CPC (TWD)'] = merged.apply(lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x['é€£çµé»æ“Šæ¬¡æ•¸'] if x['é€£çµé»æ“Šæ¬¡æ•¸'] > 0 else 0, axis=1)

    total_spend = merged['èŠ±è²»é‡‘é¡ (TWD)'].sum()
    total_conv = merged['è½‰æ›'].sum()
    merged['èŠ±è²»å æ¯”(%)'] = merged['èŠ±è²»é‡‘é¡ (TWD)'].apply(lambda v: (v / total_spend * 100) if total_spend > 0 else 0)
    merged['è½‰æ›å æ¯”(%)'] = merged['è½‰æ›'].apply(lambda v: (v / total_conv * 100) if total_conv > 0 else 0)

    merged = merged.sort_values(['is_new_adset', 'èŠ±è²»é‡‘é¡ (TWD)'], ascending=[False, False]).head(top_n)

    return merged.round(2)
# --- end ---
def create_summary_row(df, metric_cols):
    """
    metric_cols: dict
      key: æŒ‡æ¨™åç¨±ï¼Œå¦‚ 'CPA (TWD)'
      val: (numerator_col, denominator_col, multiplier)
      multiplier: 1 (ç´”æ¯”å€¼), 100 (ç™¾åˆ†æ¯”), 1000 (æ¯åƒæ¬¡ï¼Œå¦‚ CPM)
    """
    summary_dict = {}
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        summary_dict[col] = df[col].sum()
        
    for metric, (num, denom, multiplier) in metric_cols.items():
        total_num = summary_dict.get(num, 0)
        total_denom = summary_dict.get(denom, 0)
        if total_denom > 0:
            val = (total_num / total_denom) * multiplier
            summary_dict[metric] = round(val, 2)
        else:
            summary_dict[metric] = 0

    non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns
    if len(non_numeric_cols) > 0:
        summary_dict[non_numeric_cols[0]] = 'å…¨å¸³æˆ¶å¹³å‡'
        for col in non_numeric_cols[1:]:
            summary_dict[col] = '-'
    return pd.DataFrame([summary_dict])

def calculate_consolidated_metrics(df_group, conv_col):
    """
    å°ä»»ä¸€å±¤ç´šï¼ˆCampaign / AdSet / Ad / Detailï¼‰ï¼š
    - å…ˆ sum èŠ±è²» / æ›å…‰ / é»æ“Š / è½‰æ›
    - å†ç”¨ aggregated æ•¸å­—ç®— CPA / CTR / CVR / CPM
    """
    df_metrics = df_group.agg({
        'èŠ±è²»é‡‘é¡ (TWD)': 'sum',
        conv_col: 'sum',
        'é€£çµé»æ“Šæ¬¡æ•¸': 'sum',
        'æ›å…‰æ¬¡æ•¸': 'sum'
    }).reset_index()

    df_metrics = df_metrics[df_metrics['èŠ±è²»é‡‘é¡ (TWD)'] > 0]

    # CPA / CTR / CVR / CPM
    df_metrics['CPA (TWD)'] = df_metrics.apply(
        lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x[conv_col] if x[conv_col] > 0 else 0, axis=1
    )
    df_metrics['CTR (%)'] = df_metrics.apply(
        lambda x: (x['é€£çµé»æ“Šæ¬¡æ•¸'] / x['æ›å…‰æ¬¡æ•¸']) * 100 if x['æ›å…‰æ¬¡æ•¸'] > 0 else 0, axis=1
    )
    df_metrics['CVR (%)'] = df_metrics.apply(
        lambda x: (x[conv_col] / x['é€£çµé»æ“Šæ¬¡æ•¸']) * 100 if x['é€£çµé»æ“Šæ¬¡æ•¸'] > 0 else 0, axis=1
    )
    df_metrics['CPM (TWD)'] = df_metrics.apply(
        lambda x: (x['èŠ±è²»é‡‘é¡ (TWD)'] / x['æ›å…‰æ¬¡æ•¸']) * 1000 if x['æ›å…‰æ¬¡æ•¸'] > 0 else 0, axis=1
    )

    df_metrics['CPC (TWD)'] = df_metrics.apply(
        lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x['é€£çµé»æ“Šæ¬¡æ•¸'] if x['é€£çµé»æ“Šæ¬¡æ•¸'] > 0 else 0, axis=1
    )

    df_metrics = df_metrics.round(2).sort_values(by='èŠ±è²»é‡‘é¡ (TWD)', ascending=False)

    metric_config = {
        'CPA (TWD)': ('èŠ±è²»é‡‘é¡ (TWD)', conv_col, 1),
        'CTR (%)': ('é€£çµé»æ“Šæ¬¡æ•¸', 'æ›å…‰æ¬¡æ•¸', 100),
        'CVR (%)': (conv_col, 'é€£çµé»æ“Šæ¬¡æ•¸', 100),
        'CPM (TWD)': ('èŠ±è²»é‡‘é¡ (TWD)', 'æ›å…‰æ¬¡æ•¸', 1000),
        'CPC (TWD)': ('èŠ±è²»é‡‘é¡ (TWD)', 'é€£çµé»æ“Šæ¬¡æ•¸', 1)
    }
    summary_row = create_summary_row(df_metrics, metric_config)
    
    if not df_metrics.empty:
        return pd.concat([df_metrics, summary_row], ignore_index=True)
    else:
        return df_metrics

def collect_period_results(df, period_name_short, conv_col):
    df['å»£å‘Šåç¨±_clean'] = df['å»£å‘Šåç¨±'].apply(clean_ad_name)
    results = []
    
    # 0. è©³ç´°å±¤ç´šï¼šæ´»å‹• + çµ„åˆ + å»£å‘Š
    results.append((
        f'{period_name_short}_Detail_è©³ç´°(çµ„åˆ+å»£å‘Š)', 
        calculate_consolidated_metrics(df.groupby(['è¡ŒéŠ·æ´»å‹•åç¨±', 'å»£å‘Šçµ„åˆåç¨±', 'å»£å‘Šåç¨±']), conv_col)
    ))
    # 1. å»£å‘Šå±¤ç´š
    results.append(
        (f'{period_name_short}_Ad_å»£å‘Š',
         calculate_consolidated_metrics(df.groupby('å»£å‘Šåç¨±_clean'), conv_col))
    )
    # 2. å»£å‘Šçµ„åˆå±¤ç´šï¼ˆé€™è£¡ä¹Ÿæœƒæœ‰ CPMï¼‰
    results.append(
        (f'{period_name_short}_AdSet_å»£å‘Šçµ„åˆ',
         calculate_consolidated_metrics(df.groupby(['è¡ŒéŠ·æ´»å‹•åç¨±', 'å»£å‘Šçµ„åˆåç¨±']), conv_col))
    )
    # 3. è¡ŒéŠ·æ´»å‹•å±¤ç´š
    results.append(
        (f'{period_name_short}_Campaign_è¡ŒéŠ·æ´»å‹•',
         calculate_consolidated_metrics(df.groupby('è¡ŒéŠ·æ´»å‹•åç¨±'), conv_col))
    )
    
    return results

# ==========================================
# 3. ç•°å¸¸åµæ¸¬èˆ‡è¶¨å‹¢åˆ†æé‚è¼¯
# ==========================================
def check_daily_anomalies(df_p1, df_p7, level_name='è¡ŒéŠ·æ´»å‹•åç¨±'):
    p1 = df_p1[df_p1[level_name] != 'å…¨å¸³æˆ¶å¹³å‡'].copy()
    p7 = df_p7[df_p7[level_name] != 'å…¨å¸³æˆ¶å¹³å‡'].copy()
    
    if p1.empty or p7.empty:
        return pd.DataFrame()

    merged = pd.merge(p1, p7, on=level_name, suffixes=('_P1', '_P7'), how='inner')
    alerts = []
    
    for _, row in merged.iterrows():
        if row['èŠ±è²»é‡‘é¡ (TWD)_P1'] < 200: 
            continue 

        name = row[level_name]
        cpa_p1, cpa_p7 = row['CPA (TWD)_P1'], row['CPA (TWD)_P7']
        ctr_p1, ctr_p7 = row['CTR (%)_P1'], row['CTR (%)_P7']
        spend_p1 = row['èŠ±è²»é‡‘é¡ (TWD)_P1']

        if cpa_p7 > 0 and cpa_p1 > cpa_p7 * 1.3:
            diff = int(((cpa_p1 - cpa_p7) / cpa_p7) * 100)
            alerts.append({
                'å±¤ç´š': level_name,
                'åç¨±': name,
                'é¡å‹': 'ğŸ”´ CPA æš´æ¼²', 
                'æ•¸æ“šå°æ¯”': f"æ˜¨${cpa_p1:.0f} vs å‡${cpa_p7:.0f} (ğŸ”º{diff}%)",
                'å»ºè­°': 'æª¢æŸ¥ç«¶åƒ¹æˆ–å—çœ¾'
            })
            
        if ctr_p7 > 0 and ctr_p1 < ctr_p7 * 0.8:
            diff = int(((ctr_p7 - ctr_p1) / ctr_p7) * 100)
            alerts.append({
                'å±¤ç´š': level_name,
                'åç¨±': name,
                'é¡å‹': 'ğŸ“‰ CTR é©Ÿé™', 
                'æ•¸æ“šå°æ¯”': f"æ˜¨{ctr_p1}% vs å‡{ctr_p7}% (ğŸ”»{diff}%)",
                'å»ºè­°': 'ç´ æç–²ä¹/æ›´æ›ç´ æ'
            })
            
        if cpa_p1 == 0 and spend_p1 > 500:
             alerts.append({
                 'å±¤ç´š': level_name,
                 'åç¨±': name,
                 'é¡å‹': 'ğŸ›‘ é«˜èŠ±è²»0è½‰æ›', 
                 'æ•¸æ“šå°æ¯”': f"æ˜¨èŠ±è²» ${spend_p1:.0f}",
                 'å»ºè­°': 'æª¢æŸ¥è½åœ°é /è¨­å®š'
             })

    return pd.DataFrame(alerts)

def check_weekly_trends(df_p7, df_pp7, level_name='è¡ŒéŠ·æ´»å‹•åç¨±'):
    curr = df_p7[df_p7[level_name] != 'å…¨å¸³æˆ¶å¹³å‡'].copy()
    prev = df_pp7[df_pp7[level_name] != 'å…¨å¸³æˆ¶å¹³å‡'].copy()
    
    if curr.empty or prev.empty:
        return pd.DataFrame()
    
    merged = pd.merge(curr, prev, on=level_name, suffixes=('_This', '_Last'), how='inner')
    trends = []
    
    for _, row in merged.iterrows():
        if row['èŠ±è²»é‡‘é¡ (TWD)_This'] < 1000: 
            continue
        
        name = row[level_name]
        cpa_this, cpa_last = row['CPA (TWD)_This'], row['CPA (TWD)_Last']
        ctr_this, ctr_last = row['CTR (%)_This'], row['CTR (%)_Last']
        spend_this, spend_last = row['èŠ±è²»é‡‘é¡ (TWD)_This'], row['èŠ±è²»é‡‘é¡ (TWD)_Last']
        
        if cpa_last > 0 and cpa_this > cpa_last * 1.2:
            diff = int(((cpa_this - cpa_last) / cpa_last) * 100)
            trends.append({
                'å±¤ç´š': level_name,
                'åç¨±': name,
                'ç‹€æ…‹': 'âš ï¸ æˆæœ¬æƒ¡åŒ–',
                'æ•¸æ“šè®ŠåŒ–': f"${cpa_this:.0f} (vs ${cpa_last:.0f})",
                'è®ŠåŒ–å¹…åº¦': f"ğŸ”º +{diff}%",
                'è¨ºæ–·': 'ç«¶çˆ­åŠ åŠ‡æˆ–è½‰æ›ç‡ä¸‹é™'
            })
            
        if ctr_last > 0 and ctr_this < ctr_last * 0.85:
            diff = int(((ctr_last - ctr_this) / ctr_this) * 100) if ctr_this > 0 else 100
            trends.append({
                'å±¤ç´š': level_name,
                'åç¨±': name,
                'ç‹€æ…‹': 'ğŸ“‰ CTR è¡°é€€',
                'æ•¸æ“šè®ŠåŒ–': f"{ctr_this}% (vs {ctr_last}%)",
                'è®ŠåŒ–å¹…åº¦': f"ğŸ”» -{diff}%",
                'è¨ºæ–·': 'ç´ æé–‹å§‹è€åŒ–'
            })

        if spend_last > 0 and spend_this > spend_last * 1.2:
            if cpa_last > 0 and cpa_this > cpa_last * 1.1:
                trends.append({
                    'å±¤ç´š': level_name,
                    'åç¨±': name,
                    'ç‹€æ…‹': 'ğŸ’¸ æ“´é‡æ•ˆç‡å·®',
                    'æ•¸æ“šè®ŠåŒ–': f"èŠ±è²»å¢è‡³ ${spend_this:,.0f}",
                    'è®ŠåŒ–å¹…åº¦': f"CPA äº¦æ¼²",
                    'è¨ºæ–·': 'é‚Šéš›æ•ˆæ‡‰éæ¸›ï¼Œå»ºè­°æš«åœåŠ ç¢¼'
                })

    return pd.DataFrame(trends)

def get_trend_data_excel(df_p30d, conv_col):
    trend_df = df_p30d.copy()
    acc_daily = trend_df.groupby(['å¤©æ•¸']).agg({
        'èŠ±è²»é‡‘é¡ (TWD)': 'sum',
        conv_col: 'sum',
        'é€£çµé»æ“Šæ¬¡æ•¸': 'sum',
        'æ›å…‰æ¬¡æ•¸': 'sum'
    }).reset_index()
    acc_daily['è¡ŒéŠ·æ´»å‹•åç¨±'] = 'ğŸ† æ•´é«”å¸³æˆ¶ (Account Overall)'
    final_trend = acc_daily[acc_daily['èŠ±è²»é‡‘é¡ (TWD)'] > 0]
    final_trend['CPA (TWD)'] = final_trend.apply(
        lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x[conv_col] if x[conv_col] > 0 else 0,
        axis=1
    )
    final_trend['CPM (TWD)'] = final_trend.apply(
        lambda x: (x['èŠ±è²»é‡‘é¡ (TWD)'] / x['æ›å…‰æ¬¡æ•¸']) * 1000 if x['æ›å…‰æ¬¡æ•¸'] > 0 else 0,
        axis=1
    )
    final_trend['å¤©æ•¸'] = final_trend['å¤©æ•¸'].dt.strftime('%Y-%m-%d')
    return final_trend.round(2)

def build_cpm_change_table(p7_camp_df, pp7_camp_df, p30_camp_df):
    """
    å»ºç«‹è¡ŒéŠ·æ´»å‹•å±¤ç´šçš„ CPM è®ŠåŒ–è¡¨ï¼šP7D / PP7D / P30D
    """
    def prep(df, suffix):
        if df is None or df.empty:
            return pd.DataFrame(columns=['è¡ŒéŠ·æ´»å‹•åç¨±', f'CPM_{suffix}', f'èŠ±è²»é‡‘é¡_{suffix}', f'æ›å…‰æ¬¡æ•¸_{suffix}'])
        tmp = df.copy()
        cols_keep = ['è¡ŒéŠ·æ´»å‹•åç¨±', 'CPM (TWD)', 'èŠ±è²»é‡‘é¡ (TWD)', 'æ›å…‰æ¬¡æ•¸']
        cols_exist = [c for c in cols_keep if c in tmp.columns]
        tmp = tmp[cols_exist]
        tmp = tmp[tmp['è¡ŒéŠ·æ´»å‹•åç¨±'].notna()]
        tmp = tmp.rename(columns={
            'CPM (TWD)': f'CPM_{suffix}',
            'èŠ±è²»é‡‘é¡ (TWD)': f'èŠ±è²»é‡‘é¡_{suffix}',
            'æ›å…‰æ¬¡æ•¸': f'æ›å…‰æ¬¡æ•¸_{suffix}'
        })
        return tmp

    p7 = prep(p7_camp_df, 'P7D')
    pp7 = prep(pp7_camp_df, 'PP7D')
    p30 = prep(p30_camp_df, 'P30D')

    merged = p7.merge(pp7, on='è¡ŒéŠ·æ´»å‹•åç¨±', how='outer').merge(p30, on='è¡ŒéŠ·æ´»å‹•åç¨±', how='outer')
    if merged.empty:
        return merged

    for c in ['CPM_P7D', 'CPM_PP7D', 'CPM_P30D',
              'èŠ±è²»é‡‘é¡_P7D', 'èŠ±è²»é‡‘é¡_PP7D', 'èŠ±è²»é‡‘é¡_P30D',
              'æ›å…‰æ¬¡æ•¸_P7D', 'æ›å…‰æ¬¡æ•¸_PP7D', 'æ›å…‰æ¬¡æ•¸_P30D']:
        if c in merged.columns:
            merged[c] = merged[c].fillna(0)

    def pct_change(new, old):
        if old == 0:
            return None
        return round((new - old) / old * 100, 2)

    merged['CPM_é€±ç’°æ¯”è®ŠåŒ–_vs_PP7D_(%)'] = merged.apply(
        lambda x: pct_change(x['CPM_P7D'], x['CPM_PP7D']), axis=1
    )
    merged['CPM_æœˆåº¦å°æ¯”_vs_P30D_(%)'] = merged.apply(
        lambda x: pct_change(x['CPM_P7D'], x['CPM_P30D']), axis=1
    )

    if 'èŠ±è²»é‡‘é¡_P7D' in merged.columns:
        merged = merged.sort_values('èŠ±è²»é‡‘é¡_P7D', ascending=False)

    return merged

# ==========================================
# 4. Excel åŒ¯å‡ºå‡½æ•¸ï¼ˆå« AI å›è¦†ï¼‰
# ==========================================
def to_excel_single_sheet_stacked(dfs_list, prompt_text, ai_response=None):
    engine = 'xlsxwriter' if HAS_XLSXWRITER else None
    if not engine:
        pass

    output = io.BytesIO()
    try:
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            workbook = writer.book
            sheet_name = 'ğŸ“˜_å®Œæ•´åˆ†æå ±å‘Š'
            ws = workbook.add_worksheet(sheet_name)
            writer.sheets[sheet_name] = ws
            
            fmt_prompt = workbook.add_format({
                'text_wrap': True, 'valign': 'top',
                'font_size': 10, 'bg_color': '#F0F2F6'
            })
            fmt_ai_response = workbook.add_format({
                'text_wrap': True, 'valign': 'top',
                'font_size': 11, 'bg_color': '#FFF8DC',
                'border': 1
            })
            fmt_header = workbook.add_format({
                'bold': True, 'font_size': 14,
                'font_color': '#0068C9'
            })
            fmt_table_header = workbook.add_format({
                'bold': True, 'bg_color': '#E6E6E6', 'border': 1
            })
            
            current_row = 0
            
            # 1. AI åˆ†æçµæœ
            if ai_response:
                ws.merge_range('A1:K1', "ğŸ¤– Gemini AI å»£å‘Šè¨ºæ–·å ±å‘Š (AI Analysis Report)", fmt_header)
                current_row += 1
                ai_lines = ai_response.count('\n') + (len(ai_response) // 50) + 2
                ws.merge_range(current_row, 0, current_row + ai_lines, 10, ai_response, fmt_ai_response)
                current_row += ai_lines + 2
            
            # 2. System Prompt
            ws.merge_range(current_row, 0, current_row, 8, "ğŸ› ï¸ ç³»çµ±åˆ†ææŒ‡ä»¤ (System Prompt Log)", fmt_header)
            current_row += 1
            prompt_lines = prompt_text.count('\n') + 3
            ws.merge_range(current_row, 0, current_row + prompt_lines, 10, prompt_text, fmt_prompt)
            current_row += prompt_lines + 2
            
            # 3. æ•¸æ“šè¡¨
            for title, df in dfs_list:
                ws.write(current_row, 0, f"ğŸ“Œ Table: {title}", fmt_header)
                current_row += 1
                df.to_excel(writer, sheet_name=sheet_name, startrow=current_row, index=False)
                for col_num, value in enumerate(df.columns.values):
                    ws.write(current_row, col_num, value, fmt_table_header)
                current_row += len(df) + 4
                
            ws.set_column('A:A', 40)
            ws.set_column('B:Z', 15)
    except Exception:
        return None
            
    output.seek(0)
    return output.getvalue()

# ==========================================
# 5. AI åˆ†æä¸²æ¥ï¼šè¼”åŠ©å‡½å¼ï¼ˆå¤šå±¤ç´šé¤µå…¥ï¼‰
# ==========================================
def safe_to_markdown(df):
    try:
        return df.to_markdown(index=False)
    except ImportError:
        return df.to_csv(sep='|', index=False)
    except Exception:
        return df.to_string(index=False)

def get_top_by_spend(df, n=20, min_spend=0):
    if df is None or df.empty:
        return df

    tmp = df.copy()

    for col in ['è¡ŒéŠ·æ´»å‹•åç¨±', 'å»£å‘Šåç¨±_clean']:
        if col in tmp.columns:
            tmp = tmp[tmp[col] != 'å…¨å¸³æˆ¶å¹³å‡']

    if 'èŠ±è²»é‡‘é¡ (TWD)' in tmp.columns:
        tmp = tmp[tmp['èŠ±è²»é‡‘é¡ (TWD)'] >= min_spend]
        tmp = tmp.sort_values('èŠ±è²»é‡‘é¡ (TWD)', ascending=False).head(n)

    return tmp


def calc_period_overall(df_period, conv_col):
    """
    è¨ˆç®—æœŸé–“æ•´é«”ï¼ˆå¸³æˆ¶å±¤ç´šï¼‰æŒ‡æ¨™ï¼šèŠ±è²» / è½‰æ› / CPA / CTR / CPC
    - ä½¿ç”¨åŸå§‹æ˜ç´° df_period èšåˆï¼Œé¿å…å—ä¸­é–“åŒ¯ç¸½è¡¨çµæ§‹å½±éŸ¿
    """
    spend = float(df_period['èŠ±è²»é‡‘é¡ (TWD)'].sum()) if 'èŠ±è²»é‡‘é¡ (TWD)' in df_period.columns else 0.0
    conv = float(df_period[conv_col].sum()) if conv_col in df_period.columns else 0.0
    clicks = float(df_period['é€£çµé»æ“Šæ¬¡æ•¸'].sum()) if 'é€£çµé»æ“Šæ¬¡æ•¸' in df_period.columns else 0.0
    impr = float(df_period['æ›å…‰æ¬¡æ•¸'].sum()) if 'æ›å…‰æ¬¡æ•¸' in df_period.columns else 0.0

    cpa = (spend / conv) if conv > 0 else 0.0
    ctr = (clicks / impr * 100) if impr > 0 else 0.0
    cpc = (spend / clicks) if clicks > 0 else 0.0

    return {
        'spend': round(spend, 0),
        'conv': round(conv, 0),
        'cpa': round(cpa, 2),
        'ctr': round(ctr, 2),
        'cpc': round(cpc, 2),
    }

def call_gemini_analysis(
    api_key,
    alerts_daily,
    alerts_weekly,
    campaign_summary,
    adset_p7=None,
    ad_p7=None,
    trend_30d=None,
    cpm_change_table=None,
    new_creatives=None,
    new_adsets=None
):
    data_context = "\n\n# ğŸ“Š Account Data Summaryï¼ˆå¤šå±¤ç´šè¦–è§’ï¼‰\n"

    data_context += "\n## 1. Daily Alerts (P1D vs P7D Anomalies)\n"
    if alerts_daily is not None and not alerts_daily.empty:
        data_context += safe_to_markdown(alerts_daily)
    else:
        data_context += "No critical daily anomalies detected."

    data_context += "\n\n## 2. Weekly Trends (P7D vs PP7D Decline)\n"
    if alerts_weekly is not None and not alerts_weekly.empty:
        data_context += safe_to_markdown(alerts_weekly)
    else:
        data_context += "No significant weekly decline trends detected."

    data_context += "\n\n## 3. Current Week Campaign Performance (P7D)\n"
    if campaign_summary is not None and not campaign_summary.empty:
        top_campaigns = get_top_by_spend(campaign_summary, n=20, min_spend=0)
        data_context += safe_to_markdown(top_campaigns)
    else:
        data_context += "No campaign-level data available."

    if adset_p7 is not None and not adset_p7.empty:
        data_context += "\n\n## 4. P7D AdSet Performance (Top by Spend)\n"
        top_adsets = get_top_by_spend(adset_p7, n=30, min_spend=500)
        if top_adsets is not None and not top_adsets.empty:
            data_context += safe_to_markdown(top_adsets)

    if ad_p7 is not None and not ad_p7.empty:
        data_context += "\n\n## 5. P7D Ad Performance (Top by Spend)\n"
        top_ads = get_top_by_spend(ad_p7, n=50, min_spend=300)
        if top_ads is not None and not top_ads.empty:
            data_context += safe_to_markdown(top_ads)

    if trend_30d is not None and not trend_30d.empty:
        data_context += "\n\n## 6. 30D Account Daily Trend (Account Overall)\n"
        data_context += safe_to_markdown(trend_30d)

    if cpm_change_table is not None and not cpm_change_table.empty:
        data_context += "\n\n## 7. CPM Change Table (P7D vs PP7D vs P30D, Campaign Level)\n"
        data_context += safe_to_markdown(cpm_change_table)

    # æ–°ç´ æ / æ–°çµ„åˆæ‘˜è¦ï¼ˆä½ tokenï¼‰
    if new_creatives is not None and not new_creatives.empty:
        data_context += "\n\n## 8. New Creatives Summary (Recent Creatives, P7D Top)\n"
        data_context += safe_to_markdown(new_creatives)

    if new_adsets is not None and not new_adsets.empty:
        data_context += "\n\n## 9. New AdSets Summary (New AdSets by Spend Shift, P7D Top)\n"
        data_context += safe_to_markdown(new_adsets)

    full_prompt = (
        AI_CONSULTANT_PROMPT
        + data_context
        + "\n\n# User Request: è«‹æ ¹æ“šä¸Šè¿°å¤šå±¤ç´šæ•¸æ“šï¼Œç”¢ç”Ÿä¸€ä»½å»£å‘Šå„ªåŒ–è¨ºæ–·å ±å‘Šï¼Œä¸¦æ˜ç¢ºæŒ‡å‡ºï¼šæ´»å‹• / AdSet / å»£å‘Šå±¤ç´šçš„èª¿æ•´å»ºè­°ï¼Œç‰¹åˆ¥èªªæ˜ CPM è®ŠåŒ–å¦‚ä½•å½±éŸ¿ CPA èˆ‡ CPCã€‚"
    )

    with st.spinner('ğŸ¤– AI æ­£åœ¨åˆ†ææ•¸æ“šä¸­... (é€™å¯èƒ½éœ€è¦ 10â€“20 ç§’)'):
        try:
            if HAS_GENAI:
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel('gemini-2.5-pro')
                response = model.generate_content(full_prompt)
                return response.text if hasattr(response, "text") else str(response)

            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent?key={api_key}"
            headers = {'Content-Type': 'application/json'}
            data = {
                "contents": [{
                    "parts": [{"text": full_prompt}]
                }]
            }
            response = requests.post(url, headers=headers, json=data)

            if response.status_code == 200:
                result_json = response.json()
                try:
                    return result_json['candidates'][0]['content']['parts'][0]['text']
                except (KeyError, IndexError):
                    return f"âš ï¸ API å›å‚³æ ¼å¼ä¸å¦‚é æœŸ: {str(result_json)}"
            else:
                return f"âš ï¸ API é€£ç·šéŒ¯èª¤ ({response.status_code}): {response.text}"

        except Exception as e:
            return f"âŒ ç³»çµ±ç™¼ç”ŸéŒ¯èª¤: {str(e)}\nè«‹æª¢æŸ¥ API Key æ˜¯å¦æ­£ç¢ºï¼Œæˆ–è©² Key æ˜¯å¦æœ‰æ¬Šé™å­˜å– 2.5 Pro æ¨¡å‹ã€‚"

# ==========================================
# 6. ä¸»ç¨‹å¼ UI
# ==========================================
st.title("ğŸ“Š å»£å‘Šæˆæ•ˆå…¨èƒ½åˆ†æ v6.4 (Dashboard + Instant DL)")

if not HAS_GENAI:
    st.warning("â„¹ï¸ æç¤ºï¼šæœªåµæ¸¬åˆ° `google-generativeai` å¥—ä»¶ã€‚ç³»çµ±å°‡è‡ªå‹•åˆ‡æ›ç‚º **REST API å…¼å®¹æ¨¡å¼** (åªéœ€ API Key å³å¯é‹ä½œ)ã€‚")
if not HAS_XLSXWRITER:
    st.warning("âš ï¸ è­¦å‘Šï¼šæœªåµæ¸¬åˆ° `xlsxwriter` å¥—ä»¶ã€‚Excel åŒ¯å‡ºåŠŸèƒ½å¯èƒ½æœƒå¤±æ•ˆã€‚")

if 'gemini_result' not in st.session_state:
    st.session_state['gemini_result'] = None

uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ CSV å ±è¡¨æª”æ¡ˆ", type=['csv'])

if uploaded_file is not None:
    try:
        # 1. è®€å–èˆ‡æ¬„ä½åµæ¸¬
        try:
            df = pd.read_csv(uploaded_file, encoding='utf-8')
        except UnicodeDecodeError:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding='cp950')
        except Exception as e:
            st.error(f"æª”æ¡ˆè®€å–æœªçŸ¥çš„éŒ¯èª¤: {e}")
            st.stop()

        df.columns = df.columns.str.strip()
        all_columns = df.columns.tolist()
        
        # å´é‚Šæ¬„è¨­å®š
        with st.sidebar:
            st.header("âš™ï¸ åˆ†æè¨­å®š")
            
            st.subheader("ğŸ¤– AI åˆ†æè¨­å®š")
            gemini_api_key = st.text_input("Gemini API Key", type="password", placeholder="è¼¸å…¥ Key ä»¥å•Ÿç”¨ AI åˆ†æ")
            st.caption("[å–å¾— Google AI Studio Key](https://aistudio.google.com/app/apikey)")
            st.divider()
            
            suggested_idx = 0
            for idx, col in enumerate(all_columns):
                c_low = col.lower()
                if 'æˆæœ¬' in col or 'cost' in c_low: 
                    continue
                if ('free' in c_low and 'course' in c_low):
                    suggested_idx = idx
                    break
                if 'è³¼è²·' in col or 'purchase' in c_low:
                    suggested_idx = idx
                    break
                if 'è½‰æ›' in col:
                    suggested_idx = idx
                    break
                
            conversion_col = st.selectbox("ğŸ¯ ç›®æ¨™è½‰æ›æ¬„ä½:", options=all_columns, index=suggested_idx)
            
            def find_col(opts, default):
                for opt in opts:
                    for col in all_columns:
                        if opt in col:
                            return col
                return default

            spend_col = find_col(['èŠ±è²»é‡‘é¡ (TWD)', 'èŠ±è²»', 'é‡‘é¡'], 'èŠ±è²»é‡‘é¡ (TWD)')
            clicks_col = find_col(['é€£çµé»æ“Šæ¬¡æ•¸', 'é€£çµé»æ“Š'], 'é€£çµé»æ“Šæ¬¡æ•¸')
            impressions_col = find_col(['æ›å…‰æ¬¡æ•¸', 'æ›å…‰'], 'æ›å…‰æ¬¡æ•¸')

        # 2. æ•¸æ“šæ¸…æ´—
        cols_to_numeric = [spend_col, clicks_col, impressions_col, conversion_col]
        for col in cols_to_numeric:
            if col in df.columns:
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str).str.replace(',', '', regex=False)
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

        if 'å¤©æ•¸' not in df.columns:
            st.error("éŒ¯èª¤ï¼šCSV æª”æ¡ˆä¸­æ‰¾ä¸åˆ°ã€Œå¤©æ•¸ã€æ¬„ä½ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼ã€‚")
            st.stop()

        df['å¤©æ•¸'] = pd.to_datetime(df['å¤©æ•¸'], errors='coerce')
        df = df.dropna(subset=['å¤©æ•¸'])

        df_std = df.rename(columns={
            spend_col: 'èŠ±è²»é‡‘é¡ (TWD)',
            clicks_col: 'é€£çµé»æ“Šæ¬¡æ•¸',
            impressions_col: 'æ›å…‰æ¬¡æ•¸'
        })
        
        # 3. æ—¥æœŸå€é–“èˆ‡è³‡æ–™åˆ†çµ„
        if df_std.empty:
            st.error("éŒ¯èª¤ï¼šè³‡æ–™ç¶“éæ¸…æ´—å¾Œç‚ºç©ºï¼Œè«‹æª¢æŸ¥åŸå§‹æª”æ¡ˆæ˜¯å¦åŒ…å«æœ‰æ•ˆçš„æ—¥æœŸèˆ‡æ•¸æ“šã€‚")
            st.stop()

        max_date = df_std['å¤©æ•¸'].max().normalize()
        today = max_date + timedelta(days=1)
        
        p1d_start = max_date
        df_p1d = df_std[df_std['å¤©æ•¸'] == p1d_start].copy()
        
        p7d_start = today - timedelta(days=7)
        p7d_end = today - timedelta(days=1)
        pp7d_start = p7d_start - timedelta(days=7)
        pp7d_end = p7d_start - timedelta(days=1)
        p30d_start = today - timedelta(days=30)
        p30d_end = today - timedelta(days=1)
        
        df_p7d = df_std[(df_std['å¤©æ•¸'] >= p7d_start) & (df_std['å¤©æ•¸'] <= p7d_end)].copy()
        df_pp7d = df_std[(df_std['å¤©æ•¸'] >= pp7d_start) & (df_std['å¤©æ•¸'] <= pp7d_end)].copy()
        df_p30d = df_std[(df_std['å¤©æ•¸'] >= p30d_start) & (df_std['å¤©æ•¸'] <= p30d_end)].copy()

        # æ–°ç´ æ / æ–°å»£å‘Šçµ„åˆæ‘˜è¦ï¼ˆä¾› AI åˆ¤è®€ï¼šé¿å…ä¸Ÿå…¨é‡è¡¨é€ æˆ token å£“åŠ›ï¼‰
        new_creatives_df = build_new_creatives_summary(
            df_p7d=df_p7d,
            conv_col=conversion_col,
            anchor_date=max_date,
            recent_days=14,
            top_n=15,
            min_spend=300
        )

        new_adsets_df = build_new_adsets_summary(
            df_p7d=df_p7d,
            df_pp7d=df_pp7d,
            conv_col=conversion_col,
            top_n=15,
            min_spend_p7=500,
            old_spend_threshold=200
        )
        
        # å„å€é–“ Campaign å±¤ç´š
        res_p1d_camp = calculate_consolidated_metrics(df_p1d.groupby('è¡ŒéŠ·æ´»å‹•åç¨±'), conversion_col)
        res_p7d_camp = calculate_consolidated_metrics(df_p7d.groupby('è¡ŒéŠ·æ´»å‹•åç¨±'), conversion_col)
        res_pp7d_camp = calculate_consolidated_metrics(df_pp7d.groupby('è¡ŒéŠ·æ´»å‹•åç¨±'), conversion_col)
        
        # è­¦ç¤ºèˆ‡é€±è¶¨å‹¢
        alerts_daily = check_daily_anomalies(res_p1d_camp, res_p7d_camp, 'è¡ŒéŠ·æ´»å‹•åç¨±')
        alerts_weekly = check_weekly_trends(res_p7d_camp, res_pp7d_camp, 'è¡ŒéŠ·æ´»å‹•åç¨±')

        # å„å€é–“å¤šå±¤ç´šåŒ¯ç¸½
        res_p1 = collect_period_results(df_p1d, 'P1D', conversion_col)
        res_p7 = collect_period_results(df_p7d, 'P7D', conversion_col)
        res_pp7 = collect_period_results(df_pp7d, 'PP7D', conversion_col)
        res_p30 = collect_period_results(df_p30d, 'P30D', conversion_col)

        # P7D å¤šå±¤ç´š DataFrame çµ¦ AI ç”¨
        p7_detail_df = res_p7[0][1]
        p7_ad_df     = res_p7[1][1]
        p7_adset_df  = res_p7[2][1]
        p7_camp_df   = res_p7[3][1]

        # P30D è¡ŒéŠ·æ´»å‹•å±¤ç´šï¼Œç”¨æ–¼ CPM è®ŠåŒ–è¡¨
        p30_camp_df = res_p30[3][1] if len(res_p30) >= 4 else None

        # 30 æ—¥å¸³æˆ¶è¶¨å‹¢ DataFrame
        trend_30d_df = get_trend_data_excel(df_p30d, conversion_col)

        # CPM è®ŠåŒ–è¡¨
        cpm_change_df = build_cpm_change_table(
            p7_camp_df,
            res_pp7d_camp,
            p30_camp_df
        )

        # ==========================================
        # [NEW] èª¿æ•´ 1ï¼šå°‡ä¸‹è¼‰é‚è¼¯æå‰è‡³æ­¤ï¼ˆç¢ºä¿æ²’åš AI ä¹Ÿèƒ½ä¸‹è¼‰ï¼‰
        # ==========================================
        excel_stack = []
        excel_stack.append(('Trend_Daily_30D', trend_30d_df))
        if cpm_change_df is not None and not cpm_change_df.empty:
            excel_stack.append(('CPM_Change_P7D_PP7D_P30D', cpm_change_df))
        excel_stack.extend(res_p1)
        excel_stack.extend(res_p7)
        excel_stack.extend(res_pp7)
        excel_stack.extend(res_p30)
        
        # å–å¾—ç›®å‰ session state çš„çµæœ (å¯èƒ½æ˜¯ Noneï¼Œä¹Ÿå¯èƒ½æ˜¯è·‘å®Œå¾Œçš„æ–‡å­—)
        current_ai_result = st.session_state.get('gemini_result', None)
        
        # ç”¢ç”Ÿ Excel Bytes
        excel_bytes = to_excel_single_sheet_stacked(excel_stack, AI_CONSULTANT_PROMPT, current_ai_result)
        
        with st.sidebar:
            st.divider()
            if excel_bytes:
                dl_label = "ğŸ“¥ ä¸‹è¼‰å®Œæ•´åˆ†æå ±è¡¨"
                if current_ai_result:
                    dl_label += " (å« AI åˆ†æ)"
                
                st.download_button(
                    label=dl_label,
                    data=excel_bytes,
                    file_name=f"Full_Report_{max_date.strftime('%Y%m%d')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.error("Excel ç”¢ç”Ÿå¤±æ•— (xlsxwriter æœªå®‰è£)")

        # ==========================================
        # [NEW] èª¿æ•´ 2ï¼šæ–°å¢ Dashboard åˆ†é  (Tab 0)
        # ==========================================
        tab_dash, tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š è‡ªè¨‚å„€è¡¨æ¿", "ğŸ“ˆ æˆ°æƒ…å®¤ & é›™é‡ç›£æ§", "ğŸ“‘ è©³ç´°æ•¸æ“šè¡¨ (AdSet+Ad)", "ğŸ¤– AI æ·±åº¦è¨ºæ–· (Gemini)", "ğŸ§¾ é€±å ±ç”¢ç”Ÿå™¨ (LINE Markdown)"])
        
        # ========== Tab 0ï¼šè‡ªè¨‚å„€è¡¨æ¿ ==========
        with tab_dash:
            st.subheader("ğŸ“ˆ 30å¤©è¶¨å‹¢æ¯”è¼ƒå„€è¡¨æ¿")
            st.caption("å‹¾é¸ä¸åŒå°è±¡ï¼Œæ¯”è¼ƒå…¶åœ¨æŒ‡å®šæŒ‡æ¨™ä¸Šçš„æ¯æ—¥è®ŠåŒ–è¶¨å‹¢ã€‚")
            
            # 1. é¸æ“‡å±¤ç´š
            dash_level = st.radio("1. é¸æ“‡åˆ†æå±¤ç´š", ["å…¨å¸³æˆ¶ (Account)", "è¡ŒéŠ·æ´»å‹• (Campaign)", "å»£å‘Šçµ„åˆ (AdSet)", "å»£å‘Š (Ad)"], horizontal=True)
            
            # 2. æº–å‚™ç¯©é¸è³‡æ–™
            df_dash = df_p30d.copy()
            level_col_map = {
                "è¡ŒéŠ·æ´»å‹• (Campaign)": "è¡ŒéŠ·æ´»å‹•åç¨±",
                "å»£å‘Šçµ„åˆ (AdSet)": "å»£å‘Šçµ„åˆåç¨±",
                "å»£å‘Š (Ad)": "å»£å‘Šåç¨±"
            }
            
            selected_entities = []
            if dash_level == "å…¨å¸³æˆ¶ (Account)":
                df_dash['åˆ†æå°è±¡'] = 'å…¨å¸³æˆ¶'
                selected_entities = ['å…¨å¸³æˆ¶']
            else:
                target_col = level_col_map[dash_level]
                # éæ¿¾æ‰ 'å…¨å¸³æˆ¶å¹³å‡' é€™ç¨®çµ±è¨ˆè¡Œ
                unique_items = sorted([x for x in df_dash[target_col].dropna().unique() if 'å¹³å‡' not in str(x)])
                selected_entities = st.multiselect(f"2. é¸æ“‡ {dash_level} (å¯å¤šé¸æ¯”å°)", unique_items)
                
                if not selected_entities:
                    st.info("ğŸ‘† è«‹å¾ä¸Šæ–¹é¸å–®é¸æ“‡è‡³å°‘ä¸€å€‹é …ç›®ä¾†é¡¯ç¤ºåœ–è¡¨")
                else:
                    df_dash = df_dash[df_dash[target_col].isin(selected_entities)].copy()
                    df_dash['åˆ†æå°è±¡'] = df_dash[target_col]

            # 3. é¸æ“‡æŒ‡æ¨™
            metric_options = ["èŠ±è²»é‡‘é¡", "è½‰æ›æ•¸", "CPA", "CTR", "CVR", "CPC", "CPM", "æ›å…‰æ¬¡æ•¸", "é€£çµé»æ“Šæ¬¡æ•¸"]
            selected_metric = st.selectbox("3. é¸æ“‡æŒ‡æ¨™ (Yè»¸)", metric_options, index=2) # é è¨­ CPA

            if selected_entities:
                # 4. è¨ˆç®—æ¯æ—¥æ•¸æ“š
                # å…ˆä¾ æ—¥æœŸ + åˆ†æå°è±¡ Groupby Sum
                daily_agg = df_dash.groupby(['å¤©æ•¸', 'åˆ†æå°è±¡']).agg({
                    'èŠ±è²»é‡‘é¡ (TWD)': 'sum',
                    conversion_col: 'sum',
                    'é€£çµé»æ“Šæ¬¡æ•¸': 'sum',
                    'æ›å…‰æ¬¡æ•¸': 'sum'
                }).reset_index()
                
                # è¨ˆç®—è¡ç”ŸæŒ‡æ¨™
                daily_agg['CPA'] = daily_agg.apply(lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x[conversion_col] if x[conversion_col] > 0 else 0, axis=1)
                daily_agg['CTR'] = daily_agg.apply(lambda x: x['é€£çµé»æ“Šæ¬¡æ•¸'] / x['æ›å…‰æ¬¡æ•¸'] * 100 if x['æ›å…‰æ¬¡æ•¸'] > 0 else 0, axis=1)
                daily_agg['CVR'] = daily_agg.apply(lambda x: x[conversion_col] / x['é€£çµé»æ“Šæ¬¡æ•¸'] * 100 if x['é€£çµé»æ“Šæ¬¡æ•¸'] > 0 else 0, axis=1)
                daily_agg['CPC'] = daily_agg.apply(lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x['é€£çµé»æ“Šæ¬¡æ•¸'] if x['é€£çµé»æ“Šæ¬¡æ•¸'] > 0 else 0, axis=1)
                daily_agg['CPM'] = daily_agg.apply(lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x['æ›å…‰æ¬¡æ•¸'] * 1000 if x['æ›å…‰æ¬¡æ•¸'] > 0 else 0, axis=1)
                
                # å°æ‡‰ä¸­æ–‡æ¬„ä½åˆ° DataFrame æ¬„ä½
                metric_map = {
                    "èŠ±è²»é‡‘é¡": "èŠ±è²»é‡‘é¡ (TWD)",
                    "è½‰æ›æ•¸": conversion_col,
                    "CPA": "CPA",
                    "CTR": "CTR",
                    "CVR": "CVR",
                    "CPC": "CPC",
                    "CPM": "CPM",
                    "æ›å…‰æ¬¡æ•¸": "æ›å…‰æ¬¡æ•¸",
                    "é€£çµé»æ“Šæ¬¡æ•¸": "é€£çµé»æ“Šæ¬¡æ•¸"
                }
                
                plot_col = metric_map[selected_metric]
                
                # Pivot è½‰æ›æˆ st.line_chart éœ€è¦çš„æ ¼å¼ (Index=Date, Columns=Entities, Values=Metric)
                chart_data = daily_agg.pivot(index='å¤©æ•¸', columns='åˆ†æå°è±¡', values=plot_col)
                chart_data = chart_data.fillna(0)
                
                st.markdown(f"#### ğŸ“Š {selected_metric} æ¯æ—¥è®ŠåŒ–è¶¨å‹¢")
                st.line_chart(chart_data)

        # ========== Tab 1ï¼šæˆ°æƒ…å®¤ ==========
        with tab1:
            col_a, col_b = st.columns(2)
            with col_a:
                st.subheader("ğŸš¨ P1D ç·Šæ€¥è­¦ç¤º (æ˜¨æ—¥ vs å‡å€¼)")
                if not alerts_daily.empty:
                    st.dataframe(alerts_daily, hide_index=True, use_container_width=True)
                else:
                    st.success("æ˜¨æ—¥è¡¨ç¾å¹³ç©© (ç„¡ CPAæš´æ¼² / CTRé©Ÿé™)")
            
            with col_b:
                st.subheader("ğŸ“‰ P7D é€±ç’°æ¯”è¡°é€€ (æœ¬é€± vs ä¸Šé€±)")
                if not alerts_weekly.empty:
                    st.dataframe(alerts_weekly, hide_index=True, use_container_width=True)
                else:
                    st.info("æœ¬é€±ç„¡é¡¯è‘—è¡°é€€é …ç›® (CPAèˆ‡CTRçš†ç©©å®š)")

            st.divider()
            # 30æ—¥æ¦‚æ³
            total_spend = df_p30d['èŠ±è²»é‡‘é¡ (TWD)'].sum()
            total_conv = df_p30d[conversion_col].sum()
            total_impr = df_p30d['æ›å…‰æ¬¡æ•¸'].sum()
            cpa_30d = total_spend / total_conv if total_conv > 0 else 0
            cpm_30d = (total_spend / total_impr * 1000) if total_impr > 0 else 0
            
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("è¿‘30æ—¥ç¸½èŠ±è²»", f"${total_spend:,.0f}")
            c2.metric("è¿‘30æ—¥ç¸½è½‰æ›", f"{total_conv:,.0f}")
            c3.metric("è¿‘30æ—¥å¹³å‡ CPA", f"${cpa_30d:,.0f}")
            c4.metric("è¿‘30æ—¥å¹³å‡ CPM", f"${cpm_30d:,.0f}")

            # è¶¨å‹¢åœ–ï¼šèŠ±è²» vs è½‰æ›
            daily = df_p30d.groupby('å¤©æ•¸')[['èŠ±è²»é‡‘é¡ (TWD)', conversion_col, 'é€£çµé»æ“Šæ¬¡æ•¸', 'æ›å…‰æ¬¡æ•¸']].sum().reset_index()
            daily['æ—¥æœŸstr'] = daily['å¤©æ•¸'].dt.strftime('%m-%d')
            
            fig, ax1 = plt.subplots(figsize=(12, 5))
            ax2 = ax1.twinx()
            ax1.bar(daily['æ—¥æœŸstr'], daily['èŠ±è²»é‡‘é¡ (TWD)'], alpha=0.6, label='èŠ±è²»')
            ax2.plot(daily['æ—¥æœŸstr'], daily[conversion_col], marker='o', label='è½‰æ›æ•¸', linewidth=2)
            ax1.set_xlabel('æ—¥æœŸ', fontproperties=font_prop)
            ax1.set_ylabel('èŠ±è²» (TWD)', fontproperties=font_prop)
            ax2.set_ylabel('è½‰æ›æ•¸', fontproperties=font_prop)
            if font_prop:
                for label in ax1.get_xticklabels():
                    label.set_fontproperties(font_prop)
            st.pyplot(fig)

            st.divider()
            st.subheader("ğŸ’° CPM è®ŠåŒ–æ¦‚æ³ï¼ˆè¡ŒéŠ·æ´»å‹•å±¤ç´šï¼šP7D / PP7D / P30Dï¼‰")
            if cpm_change_df is not None and not cpm_change_df.empty:
                st.dataframe(cpm_change_df, use_container_width=True)
            else:
                st.info("ç›®å‰ç„¡æ³•ç”¢ç”Ÿ CPM è®ŠåŒ–è¡¨ï¼ˆå¯èƒ½æ˜¯è³‡æ–™ä¸è¶³æˆ–æ¬„ä½ä¸å®Œæ•´ï¼‰ã€‚")

        # ========== Tab 2ï¼šè©³ç´°æ•¸æ“šè¡¨ ==========
        with tab2:
            st.markdown("### ğŸ” å„å€é–“è©³ç´°æ•¸æ“š (è¡ŒéŠ·æ´»å‹• > å»£å‘Šçµ„åˆ > å»£å‘Š)")
            t_p1, t_p7, t_pp7, t_p30 = st.tabs(["P1D (æ˜¨æ—¥)", "P7D (æœ¬é€±)", "PP7D (ä¸Šé€±)", "P30D (æœˆå ±)"])
            
            def render_data_tab(results_list, unique_key):
                st.info("ğŸ’¡ ä¸‹è¡¨ç‚ºã€Œè©³ç´°å±¤ç´šã€ï¼Œå¯çœ‹åˆ°æ¯å€‹ è¡ŒéŠ·æ´»å‹• > å»£å‘Šçµ„åˆ > å»£å‘Š çš„è¡¨ç¾ï¼ˆå« CPA / CTR / CVR / CPMï¼‰ã€‚")
                st.dataframe(results_list[0][1], use_container_width=True)
                
                with st.expander("æŸ¥çœ‹å…¶ä»–åŒ¯ç¸½å±¤ç´š (è¡ŒéŠ·æ´»å‹• / å»£å‘Šçµ„åˆ / å»£å‘Šæ•´é«”)"):
                    view_mode = st.radio(
                        "é¸æ“‡å…¶ä»–æª¢è¦–å±¤ç´š:", 
                        ["è¡ŒéŠ·æ´»å‹• (Campaign)", "å»£å‘Šçµ„åˆ (AdSet)", "å»£å‘Š (Ad)"],
                        horizontal=True,
                        key=unique_key
                    )
                    if view_mode == "è¡ŒéŠ·æ´»å‹• (Campaign)":
                        st.dataframe(results_list[3][1], use_container_width=True)
                    elif view_mode == "å»£å‘Šçµ„åˆ (AdSet)":
                        st.dataframe(results_list[2][1], use_container_width=True)
                    elif view_mode == "å»£å‘Š (Ad)":
                        st.dataframe(results_list[1][1], use_container_width=True)

            with t_p1:
                render_data_tab(res_p1, "radio_p1")
            with t_p7:
                render_data_tab(res_p7, "radio_p7")
            with t_pp7:
                render_data_tab(res_pp7, "radio_pp7")
            with t_p30:
                render_data_tab(res_p30, "radio_p30")

        # ========== Tab 3ï¼šAI æ·±åº¦è¨ºæ–· ==========
        with tab3:
            st.header("ğŸ¤– Gemini AI å»£å‘Šæˆæ•ˆè¨ºæ–·")
            st.markdown("""
AI å°‡ä¾ç…§ã€Œå¸³æˆ¶å±¤ç´š â†’ è¡ŒéŠ·æ´»å‹• â†’ AdSet â†’ å»£å‘Š â†’ 30 æ—¥è¶¨å‹¢ â†’ CPM è®ŠåŒ–ã€çš„å¤šå±¤ç´šæ•¸æ“šï¼Œ
è‡ªå‹•ç”¢ç”Ÿå„ªåŒ–è¨ºæ–·å ±å‘Šèˆ‡å¯åŸ·è¡Œå»ºè­°ï¼Œä¸¦ç‰¹åˆ¥èªªæ˜ CPM è®ŠåŒ–å° CPA / CPC çš„å½±éŸ¿ã€‚
            """)
            
            col_ai_btn, _ = st.columns([1, 2])
            with col_ai_btn:
                run_ai = st.button("ğŸš€ é–‹å§‹ AI æ™ºèƒ½åˆ†æ", type="primary")
            
            if run_ai:
                if not gemini_api_key:
                    st.warning("âš ï¸ è«‹å…ˆæ–¼å·¦å´å´é‚Šæ¬„è¼¸å…¥ Gemini API Key")
                else:
                    analysis_result = call_gemini_analysis(
                        api_key=gemini_api_key,
                        alerts_daily=alerts_daily,
                        alerts_weekly=alerts_weekly,
                        campaign_summary=p7_camp_df,
                        adset_p7=p7_adset_df,
                        ad_p7=p7_ad_df,
                        trend_30d=trend_30d_df,
                        cpm_change_table=cpm_change_df,
                        new_creatives=new_creatives_df,
                        new_adsets=new_adsets_df
                    )
                    st.session_state['gemini_result'] = analysis_result
                    # å¼·åˆ¶é‡æ–°åŸ·è¡Œä¸€æ¬¡ä»¥åˆ·æ–°å´é‚Šæ¬„ä¸‹è¼‰æŒ‰éˆ•çš„å…§å®¹
                    st.rerun()
            
            if st.session_state['gemini_result']:
                st.markdown("### ğŸ“ AI è¨ºæ–·å ±å‘Š")
                st.markdown("---")
                st.markdown(st.session_state['gemini_result'])


        # ========== Tab 4ï¼šé€±å ±ç”¢ç”Ÿå™¨ï¼ˆLINE Markdownï¼‰ ==========
        PLAN_TYPES = [
            "1. åšç°¡æ˜“çš„é–‹é—œã€é ç®—èª¿é…å³å¯",
            "2. è£œç´ æ",
            "3. è£œå—çœ¾",
            "4. é€²è¡Œåˆ°é”é é¢å„ªåŒ–",
            "5. é ç®—ç¸®æ¸›ã€æé«˜",
            "6. ç¶­æŒå³å¯",
        ]

        def _fmt_pct(x):
            return f"{x:.2f}%"

        def _fmt_money(x):
            return f"${x:,.0f}"

        def _weekly_report_ai_prompt(p7_overall, pp7_overall, top_adsets_p7, top_ads_p7):
            return f"""
ä½ æ˜¯ä¸€ä½æˆæ•ˆå»£å‘Šä»£æ“é¡§å•ã€‚è«‹ç”¨ã€Œå¯ç›´æ¥è²¼çµ¦å®¢æˆ¶çš„é€±å ±èªæ°£ã€è¼¸å‡ºç¹é«”ä¸­æ–‡ï¼Œä¿æŒç°¡æ½”ã€å¯åŸ·è¡Œã€‚

ã€æœ¬é€± P7D æ¦‚æ³ã€‘
- èŠ±è²»ï¼š{p7_overall['spend']}
- è½‰æ›ï¼š{p7_overall['conv']}
- CPAï¼š{p7_overall['cpa']}
- CTRï¼š{p7_overall['ctr']}%
- CPCï¼š{p7_overall['cpc']}

ã€ä¸Šé€± PP7D æ¦‚æ³ã€‘
- èŠ±è²»ï¼š{pp7_overall['spend']}
- è½‰æ›ï¼š{pp7_overall['conv']}
- CPAï¼š{pp7_overall['cpa']}
- CTRï¼š{pp7_overall['ctr']}%
- CPCï¼š{pp7_overall['cpc']}

ã€AdSetï¼ˆè¦–ç‚ºå—çœ¾å–®ä½ï¼‰P7D Topã€‘
{safe_to_markdown(top_adsets_p7)}

ã€Adï¼ˆè¦–ç‚ºç´ æå–®ä½ï¼‰P7D Topã€‘
{safe_to_markdown(top_ads_p7)}

è«‹è¼¸å‡º JSONï¼ˆå‹™å¿…æ˜¯ JSONï¼Œä¸èƒ½æœ‰å¤šé¤˜æ–‡å­—ï¼‰ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "status_summary": "ä¸€æ®µ 2~4 å¥çš„ç¾æ³æè¿°ï¼ˆåŒ…å«ï¼šå“ªäº›å—çœ¾æœ‰æ•ˆ/ç„¡æ•ˆã€å“ªäº›ç´ ææœ‰æ•ˆ/ç„¡æ•ˆï¼‰",
  "audience_effective": ["å—çœ¾/AdSet Aï¼ˆç†ç”±ï¼‰", "..."],
  "audience_ineffective": ["å—çœ¾/AdSet Bï¼ˆç†ç”±ï¼‰", "..."],
  "creative_effective": ["ç´ æ/Ad Xï¼ˆç†ç”±ï¼‰", "..."],
  "creative_ineffective": ["ç´ æ/Ad Yï¼ˆç†ç”±ï¼‰", "..."],
  "next_week_plan_reco": [
    {{
      "type": "1. åšç°¡æ˜“çš„é–‹é—œã€é ç®—èª¿é…å³å¯",
      "recommend": true,
      "reason": "ç‚ºä½•å»ºè­°/ä¸å»ºè­°",
      "actions": ["å…·é«”å‹•ä½œ 1", "å…·é«”å‹•ä½œ 2"]
    }}
  ]
}}
"""

        def _try_parse_json(s):
            try:
                return json.loads(s)
            except Exception:
                s2 = re.sub(r"^```json\s*|\s*```$", "", str(s).strip(), flags=re.IGNORECASE)
                try:
                    return json.loads(s2)
                except Exception:
                    return None

        with tab4:
            st.subheader("ğŸ§¾ æ¯é€±å‘¨å ±ï¼ˆå¯è²¼ LINEï¼‰")
            st.caption("æµç¨‹ï¼šAI å…ˆç”¢è‰æ¡ˆ â†’ ä½ å‹¾é¸/ç·¨è¼¯ â†’ ç”¢å‡º Markdown")

            # 1) P7D / PP7D å¸³æˆ¶æ¦‚æ³
            p7_overall = calc_period_overall(df_p7d, conversion_col)
            pp7_overall = calc_period_overall(df_pp7d, conversion_col)

            # 2) å–å—çœ¾/ç´ æ Topï¼ˆé¿å…æŠŠæ•´å¼µè¡¨ä¸Ÿçµ¦ AI å¤ªé•·ï¼‰
            top_adsets = get_top_by_spend(p7_adset_df, n=12, min_spend=500)
            top_ads = get_top_by_spend(p7_ad_df, n=12, min_spend=300)

            # 3) é¡¯ç¤ºæ¦‚æ³
            c1, c2 = st.columns(2)
            with c1:
                st.markdown("**P7D æ¦‚æ³**")
                st.write({
                    "èŠ±è²»": _fmt_money(p7_overall["spend"]),
                    "è½‰æ›": int(p7_overall["conv"]),
                    "CPA": _fmt_money(p7_overall["cpa"]),
                    "CTR": _fmt_pct(p7_overall["ctr"]),
                    "CPC": _fmt_money(p7_overall["cpc"]),
                })
            with c2:
                st.markdown("**PP7D æ¦‚æ³**")
                st.write({
                    "èŠ±è²»": _fmt_money(pp7_overall["spend"]),
                    "è½‰æ›": int(pp7_overall["conv"]),
                    "CPA": _fmt_money(pp7_overall["cpa"]),
                    "CTR": _fmt_pct(pp7_overall["ctr"]),
                    "CPC": _fmt_money(pp7_overall["cpc"]),
                })

            st.divider()

            # 4) ç”Ÿæˆé€±å ±è‰æ¡ˆï¼ˆAIï¼‰
            if "weekly_draft" not in st.session_state:
                st.session_state["weekly_draft"] = None

            col_btn, col_hint = st.columns([1, 3])
            with col_btn:
                gen_weekly = st.button("ğŸ¤– ç”Ÿæˆé€±å ±è‰æ¡ˆ", type="primary")
            with col_hint:
                st.info("æœƒè¼¸å‡ºï¼šç¾æ³æè¿° / æœ‰æ•ˆç„¡æ•ˆå—çœ¾èˆ‡ç´ æ / ä¸‹é€±è¨ˆç•«ï¼ˆ6 é¡ï¼‰â†’ ä½ å†å‹¾é¸èˆ‡æ”¹å­—")

            if gen_weekly:
                if not gemini_api_key:
                    st.warning("âš ï¸ è«‹å…ˆæ–¼å·¦å´å´é‚Šæ¬„è¼¸å…¥ Gemini API Key")
                else:
                    prompt = _weekly_report_ai_prompt(p7_overall, pp7_overall, top_adsets, top_ads)
                    with st.spinner("AI é€±å ±è‰æ¡ˆç”Ÿæˆä¸­..."):
                        try:
                            if HAS_GENAI:
                                genai.configure(api_key=gemini_api_key)
                                model = genai.GenerativeModel("gemini-2.5-pro")
                                resp = model.generate_content(prompt)
                                raw_text = resp.text if hasattr(resp, "text") else str(resp)
                            else:
                                url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent?key={gemini_api_key}"
                                headers = {"Content-Type": "application/json"}
                                data = {"contents": [{"parts": [{"text": prompt}]}]}
                                r = requests.post(url, headers=headers, json=data)
                                if r.status_code == 200:
                                    j = r.json()
                                    raw_text = j["candidates"][0]["content"]["parts"][0]["text"]
                                else:
                                    raw_text = ""
                        except Exception as e:
                            raw_text = ""

                    parsed = _try_parse_json(raw_text)
                    if not parsed:
                        st.error("AI å›å‚³ä¸æ˜¯å¯è§£æ JSONï¼ˆå¯èƒ½æ··å…¥å…¶å®ƒæ–‡å­—ï¼‰ã€‚ä½ å¯ä»¥æŠŠå›å‚³è²¼åˆ°ä¸‹æ–¹æ‰‹å‹•ä¿®æ­£ã€‚")
                        st.text_area("AI åŸå§‹å›å‚³", value=str(raw_text), height=220)
                    else:
                        st.session_state["weekly_draft"] = parsed

            draft = st.session_state.get("weekly_draft")
            if not draft:
                st.stop()

            st.divider()
            st.subheader("âœï¸ ä½ å¯å‹¾é¸ã€ç·¨è¼¯ã€è£œå……")

            # 5) ç¾æ³æè¿°ï¼ˆå¯ç·¨è¼¯ï¼‰
            status_summary = st.text_area(
                "ç¾æ³æè¿°ï¼ˆå¯æ”¹ï¼‰",
                value=str(draft.get("status_summary", "")),
                height=120
            )

            # 6) æœ‰æ•ˆ/ç„¡æ•ˆå—çœ¾èˆ‡ç´ æï¼šå‹¾é¸ + å¯ç·¨è¼¯
            def editable_checklist(title, items, key_prefix):
                st.markdown(f"### {title}")
                chosen = []

                items = items or []
                for i, it in enumerate(items):
                    k_chk = f"{key_prefix}_chk_{i}"
                    k_txt = f"{key_prefix}_txt_{i}"

                    # åªåœ¨ widget å»ºç«‹å‰åˆå§‹åŒ–é è¨­å€¼ï¼ˆä¸€æ¬¡ï¼‰
                    if k_chk not in st.session_state:
                        st.session_state[k_chk] = True
                    if k_txt not in st.session_state:
                        st.session_state[k_txt] = str(it)

                    # ç”± widget è‡ªè¡Œæ›´æ–° session_stateï¼Œé¿å…é‡è¤‡è³¦å€¼é€ æˆéŒ¯èª¤
                    st.checkbox("æ¡ç”¨", key=k_chk)
                    st.text_input("å…§å®¹", key=k_txt)

                    if st.session_state.get(k_chk) and str(st.session_state.get(k_txt, "")).strip():
                        chosen.append(str(st.session_state.get(k_txt, "")).strip())

                    st.divider()

                return chosen

            colL, colR = st.columns(2)
            with colL:
                aud_eff = editable_checklist("âœ… æœ‰æ•ˆå—çœ¾ï¼ˆAdSetï¼‰", draft.get("audience_effective", []), "aud_eff")
                aud_bad = editable_checklist("âŒ ç„¡æ•ˆå—çœ¾ï¼ˆAdSetï¼‰", draft.get("audience_ineffective", []), "aud_bad")
            with colR:
                cre_eff = editable_checklist("âœ… æœ‰æ•ˆç´ æï¼ˆAdï¼‰", draft.get("creative_effective", []), "cre_eff")
                cre_bad = editable_checklist("âŒ ç„¡æ•ˆç´ æï¼ˆAdï¼‰", draft.get("creative_ineffective", []), "cre_bad")

            st.divider()

            # 7) ä¸‹é€±è¨ˆç•«ï¼š6 é¡å‹é€ä¸€é¡¯ç¤ºï¼ˆå‹¾é¸æ¡ç”¨ + ç·¨è¼¯ç†ç”± + ç·¨è¼¯ actionsï¼‰
            st.markdown("### ğŸ“Œ ä¸‹é€±è¨ˆç•«ï¼ˆä½ æ±ºå®šæ¡ç”¨å“ªäº›ï¼‰")
            plan_recos = draft.get("next_week_plan_reco", [])

            reco_map = {p.get("type"): p for p in plan_recos if isinstance(p, dict) and p.get("type")}
            merged_plans = []
            for t in PLAN_TYPES:
                p = reco_map.get(t, {"type": t, "recommend": False, "reason": "", "actions": []})
                merged_plans.append(p)

            selected_plans = []
            for idx, p in enumerate(merged_plans):
                t = p.get("type", "")
                default_on = bool(p.get("recommend", False))

                k_on = f"plan_on_{idx}"
                k_reason = f"plan_reason_{idx}"
                k_actions = f"plan_actions_{idx}"

                if k_on not in st.session_state:
                    st.session_state[k_on] = default_on
                if k_reason not in st.session_state:
                    st.session_state[k_reason] = str(p.get("reason", ""))
                if k_actions not in st.session_state:
                    st.session_state[k_actions] = "\n".join(p.get("actions", []) or [])

                st.markdown(f"**{t}**")
                st.checkbox("æ¡ç”¨æ­¤è¨ˆç•«", key=k_on)
                st.text_area("ç†ç”±ï¼ˆå¯æ”¹ï¼‰", height=80, key=k_reason)
                st.text_area("å…·é«”å‹•ä½œï¼ˆæ¯è¡Œä¸€æ¢ï¼Œå¯æ”¹ï¼‰", height=100, key=k_actions)

                if st.session_state[k_on]:
                    actions_list = [x.strip() for x in st.session_state[k_actions].splitlines() if x.strip()]
                    selected_plans.append({
                        "type": t,
                        "reason": st.session_state[k_reason].strip(),
                        "actions": actions_list
                    })
                st.divider()

            # 8) è£œå……è¼¸å…¥æ¡†
            client_note = st.text_area("è£œå……èªªæ˜ï¼ˆå¯é¸ï¼‰", value="", height=120)

            # 9) æ‹¼ Markdownï¼ˆLINE å¯è²¼ï¼‰
            def build_markdown():
                lines = []
                lines.append("## ğŸ“Š æœ¬é€±å»£å‘Šé€±å ±")
                lines.append("")
                lines.append("### 1) ç°¡è¦æ¦‚æ³")
                lines.append(f"- **P7D** èŠ±è²» {_fmt_money(p7_overall['spend'])}ï½œè½‰æ› {int(p7_overall['conv'])}ï½œCPA {_fmt_money(p7_overall['cpa'])}ï½œCTR {_fmt_pct(p7_overall['ctr'])}ï½œCPC {_fmt_money(p7_overall['cpc'])}")
                lines.append(f"- **PP7D** èŠ±è²» {_fmt_money(pp7_overall['spend'])}ï½œè½‰æ› {int(pp7_overall['conv'])}ï½œCPA {_fmt_money(pp7_overall['cpa'])}ï½œCTR {_fmt_pct(pp7_overall['ctr'])}ï½œCPC {_fmt_money(pp7_overall['cpc'])}")
                lines.append("")
                lines.append("### 2) ç¾æ³æè¿°")
                if status_summary.strip():
                    lines.append(status_summary.strip())
                lines.append("")
                lines.append("### 3) å—çœ¾èˆ‡ç´ æè¡¨ç¾")
                if aud_eff:
                    lines.append("**âœ… æœ‰æ•ˆå—çœ¾ï¼ˆAdSetï¼‰**")
                    lines += [f"- {x}" for x in aud_eff]
                if aud_bad:
                    lines.append("**âŒ ç„¡æ•ˆå—çœ¾ï¼ˆAdSetï¼‰**")
                    lines += [f"- {x}" for x in aud_bad]
                if cre_eff:
                    lines.append("**âœ… æœ‰æ•ˆç´ æï¼ˆAdï¼‰**")
                    lines += [f"- {x}" for x in cre_eff]
                if cre_bad:
                    lines.append("**âŒ ç„¡æ•ˆç´ æï¼ˆAdï¼‰**")
                    lines += [f"- {x}" for x in cre_bad]
                lines.append("")
                lines.append("### 4) ä¸‹é€±è¨ˆç•«")
                if selected_plans:
                    for p in selected_plans:
                        lines.append(f"**{p['type']}**")
                        if p.get("reason"):
                            lines.append(f"- ç†ç”±ï¼š{p['reason']}")
                        if p.get("actions"):
                            lines.append("- å‹•ä½œï¼š")
                            lines += [f"  - {a}" for a in p["actions"]]
                else:
                    lines.append("- æœ¬é€±å»ºè­°ç¶­æŒç‚ºä¸»ï¼Œå…ˆè§€å¯Ÿæ•¸æ“šç©©å®šæ€§ã€‚")
                if client_note.strip():
                    lines.append("")
                    lines.append("### 5) è£œå……")
                    lines.append(client_note.strip())
                return "\n".join(lines)

            md = build_markdown()

            st.subheader("ğŸ“‹ å¯è¤‡è£½ Markdownï¼ˆè²¼çµ¦å®¢æˆ¶ï¼‰")
            st.code(md, language="markdown")

    except Exception as e:
        st.error(f"ç³»çµ±ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}")
        st.write("å»ºè­°æª¢æŸ¥ï¼š1. CSVæ ¼å¼æ˜¯å¦æ­£ç¢º 2. æ˜¯å¦åŒ…å«è½‰æ›/èŠ±è²»/æ›å…‰æ¬„ä½")
