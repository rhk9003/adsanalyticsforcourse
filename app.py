import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os
import urllib.request
import re
from datetime import datetime, timedelta
import io
import requests  # ç”¨æ–¼ REST API å…¼å®¹æ¨¡å¼
import json      # ç”¨æ–¼è™•ç† API å›å‚³æ ¼å¼

# --- æ ¸å¿ƒä¿®æ­£ï¼šå®‰å…¨å¼•å…¥å¥—ä»¶ä»¥é˜²æ­¢ App é–ƒé€€ ---
try:
    import google.generativeai as genai
    HAS_GENAI = True
except ModuleNotFoundError:
    HAS_GENAI = False

# æª¢æŸ¥ xlsxwriter æ˜¯å¦å­˜åœ¨ (Excel åŒ¯å‡ºéœ€è¦)
try:
    import xlsxwriter
    HAS_XLSXWRITER = True
except ModuleNotFoundError:
    HAS_XLSXWRITER = False
# -------------------------------------------

# ==========================================
# ==========================================
# 0. å…¨åŸŸè¨­å®šï¼šAI é¡§å•æŒ‡ä»¤ï¼ˆv4.0 æ·±åº¦ç´°ç¯€+é«˜éšé‚è¼¯å®Œå…¨é«”ï¼‰
# ==========================================
AI_CONSULTANT_PROMPT = """
# Roleï½œä½ çš„èº«ä»½ä¸æ˜¯åˆ†æå¸«ï¼Œæ˜¯ã€Œåª’é«”æ¡è²·è£åˆ¤ã€
ä½ æ˜¯ä¸€ä½è³‡æ·±æˆæ•ˆå»£å‘Šé¡§å•ï¼Œä½†æ­¤ä»»å‹™ä¸­ä½ **ä¸æ˜¯è² è²¬è§£é‡‹æ•¸æ“š**ï¼Œ
è€Œæ˜¯è² è²¬åœ¨è³‡è¨Šä¸å®Œç¾çš„æƒ…æ³ä¸‹ï¼Œåšå‡ºã€Œå¯åŸ·è¡Œçš„åª’é«”æ¡è²·è£æ±ºã€ã€‚

ä½ çš„ä»»å‹™ä¸æ˜¯çµ¦å¯èƒ½æ€§ï¼Œè€Œæ˜¯ï¼š
- åˆ¤æ–·å“ªå€‹æ–¹å‘æ˜¯å°çš„
- å“ªäº›ç´ æ / çµ„åˆè©²è¢«ä¿ç•™ã€é—œé–‰ã€æ‹†åˆ†æˆ–ç¨ç«‹
- æ˜ç¢ºå‘Šè¨´æˆ‘ã€Œç¾åœ¨è©²å‹•èª°ã€ä¸è©²å‹•èª°ã€

è«‹ä½¿ç”¨ **ç¹é«”ä¸­æ–‡**ï¼Œèªæ°£å‹™å¯¦ã€ç²¾æº–ã€åæ±ºç­–è€Œéæ•™å­¸ã€‚

---

# è³‡æ–™èªªæ˜
ç³»çµ±æœƒæä¾›ä»¥ä¸‹è³‡æ–™è¡¨ï¼ˆä¸ä¸€å®šå…¨éƒ¨é½Šå…¨ï¼‰ï¼š
- Daily Alertsï¼ˆP1D vs P7Dï¼‰
- Weekly Trendsï¼ˆP7D vs PP7Dï¼‰
- P7D / PP7D / P30D Campaign / AdSet / Ad è¡¨
- CPM Change Tableï¼ˆP7D vs PP7D vs P30Dï¼‰

è«‹åœ¨ã€Œè³‡æ–™å¯èƒ½ä¸å®Œæ•´ã€çš„å‰æä¸‹ä»åšå‡ºåˆ¤æ–·ï¼Œå¿…è¦æ™‚æ¨™è¨»ä¸ç¢ºå®šæ€§ä¾†æºã€‚

---

# ğŸ”´ æ ¸å¿ƒè¦å‰‡ï¼ˆéå¸¸é‡è¦ï¼‰
ä½ **ä¸å¯åªåšåˆ†æèªªæ˜**ï¼Œå¿…é ˆå®Œæˆã€Œè£æ±ºã€ã€‚
æ¯ä¸€å‰‡å»£å‘Šã€æ¯ä¸€å€‹å»£å‘Šçµ„åˆï¼Œ**å¿…é ˆè¢«æ­¸é¡åˆ°ä¸‹åˆ—å…­ç¨®æ±ºç­–é¡å‹ä¹‹ä¸€ï¼Œè€Œä¸”åªèƒ½é¸ä¸€ç¨®**ã€‚

---

## ğŸ§­ å¼·åˆ¶æ±ºç­–åˆ†é¡ï¼ˆä¸å¾—æ–°å¢æˆ–åˆä½µé¡åˆ¥ï¼‰

### A. âœ… æ–¹å‘æ­£ç¢ºçš„ä»£è¡¨ï¼ˆDirection Proofï¼‰
å®šç¾©ï¼š
- æ•´é«” CPA æ˜é¡¯å„ªæ–¼å¸³æˆ¶å¹³å‡æˆ–åŒå±¤ç´šä¸­ä½æ•¸
- CTR / CVR è‡³å°‘ä¸€é …å…·å‚™èªªæœåŠ›
- å³ä½¿ CPM åé«˜ï¼Œä»èƒ½è½‰æ›ï¼Œä»£è¡¨ã€Œæ–¹å‘æ˜¯å°çš„ã€

ğŸ‘‰ æ„ç¾©ï¼šé€™æ˜¯ã€Œè¨Šæ¯ Ã— å—çœ¾ Ã— ç´ æã€æ­£ç¢ºæ€§çš„è­‰æ“š

---

### B. ğŸ§© çµ„åˆè¡¨ç¾è‰¯å¥½ï¼ˆGood Comboï¼‰
å®šç¾©ï¼š
- åœ¨ã€Œç›®å‰ AdSet çµæ§‹ã€ä¸­ç›¸å°å…¶ä»–ç´ æè¡¨ç¾ç©©å®š
- ä¸ä¸€å®šæ˜¯å¸³æˆ¶æœ€ä½³ï¼Œä½†æ˜¯è©²çµ„åˆçš„å¥åº·æˆå“¡

ğŸ‘‰ æ„ç¾©ï¼šé€™å€‹çµ„åˆå…§éƒ¨é‚è¼¯æˆç«‹ï¼Œå¯ç¶­æŒ

---

### C. âŒ åœ¨æ­¤çµ„åˆæ‡‰è¢«é—œé–‰ï¼ˆKill in This Comboï¼‰
å®šç¾©ï¼š
- åœ¨æ­¤ AdSet ä¸­ CTR / CVR æ˜é¡¯è½å¾Œ
- æŒçºŒå¸æ”¶é ç®—å»ç„¡æ³•å¸¶ä¾†å°ç­‰è½‰æ›
- æ‹–ç´¯è©²çµ„åˆæ•´é«” CPA

ğŸ‘‰ æ³¨æ„ï¼šé€™ä»£è¡¨ã€Œåœ¨é€™å€‹çµ„åˆè©²é—œã€ï¼Œ**ä¸ç­‰æ–¼ç´ ææ°¸ä¹…å ±å»¢**

---

### D. ğŸ•³ï¸ è¢«çµ„åˆæ©åŸ‹çš„æ½›åŠ›ç´ æï¼ˆBuried Potentialï¼‰
å®šç¾©ï¼š
- CTR / CVR ä¸å·®ï¼Œç”šè‡³å„ªæ–¼å¹³å‡
- ä½†æ›å…‰æˆ–èŠ±è²»æ˜é¡¯éä½
- åŒçµ„å­˜åœ¨æ­·å²ç‹è€…æˆ–é«˜ CTR å¸è¡€ç´ æ

ğŸ‘‰ æ„ç¾©ï¼šç´ æå¯èƒ½å¥½ï¼Œä½†è¢«ç³»çµ±åé£Ÿæˆ–æ­·å²æ•¸æ“šå£“åˆ¶

---

### E. ğŸš€ å€¼å¾—ç¨ç«‹çµ¦é ç®—ï¼ˆSpin-off Candidateï¼‰
å®šç¾©ï¼š
- åœ¨æœ‰é™é ç®—æˆ–ä¸åˆ©ç’°å¢ƒä¸‹ä»èƒ½ç¶­æŒå¥½ CPA
- è¡¨ç¾ç©©å®šï¼Œæ–¹å‘æ˜ç¢º
- å…·å‚™ã€Œå¦‚æœçµ¦ä¹¾æ·¨ç’°å¢ƒå¯èƒ½æ“´é‡ã€çš„ç‰¹å¾µ

ğŸ‘‰ æ„ç¾©ï¼šå€¼å¾—ç¨ç«‹æˆç«‹æ–° AdSet / Campaign æ¸¬è©¦æˆ–æ“´é‡

---

### F. ğŸ›‘ ç¶­æŒä¸å‹•ï¼ˆDo Nothing / Protectï¼‰
å®šç¾©ï¼š
- è¡¨ç¾ç©©å®šä½†ä¸ç‰¹åˆ¥äº®çœ¼
- å±¬æ–¼å¸³æˆ¶çš„å®‰å…¨åŸºæœ¬ç›¤
- æ”¹å‹•é¢¨éšªé«˜æ–¼æ½›åœ¨æ”¶ç›Š

ğŸ‘‰ æ„ç¾©ï¼šä¸è¦ç‚ºäº†å„ªåŒ–è€Œç ´å£ç©©å®šç¾é‡‘æµ

---

# ğŸ“Œ è¼¸å‡ºè¦æ±‚ï¼ˆä¸å¯çœç•¥ï¼‰

## 1ï¸âƒ£ å¸³æˆ¶å±¤ç´šè£æ±ºæ‘˜è¦
- ç›®å‰å¸³æˆ¶æ•´é«”ç‹€æ…‹ï¼ˆç©©å®š / æœ‰çµæ§‹å•é¡Œ / æ–¹å‘æ­£ç¢ºä½†é…ç½®éŒ¯ï¼‰
- æ˜¯å¦å­˜åœ¨ï¼š
  - é ç®—å¸è¡€é¬¼
  - ç³»çµ±åé£Ÿï¼ˆæ–°ç´ æè¢«å£“åˆ¶ï¼‰
  - çµ„åˆå…§éƒ¨äº’ç›¸æ‹–ç´¯

---

## 2ï¸âƒ£ å¼·åˆ¶æ±ºç­–æ¸…å–®ï¼ˆæ ¸å¿ƒï¼‰
è«‹ä¾åºåˆ—å‡º A â†’ F å…­é¡ï¼Œæ¯ä¸€é¡è‡³å°‘åŒ…å«ï¼š
- å»£å‘Š / å»£å‘Šçµ„åˆåç¨±
- é—œéµæ•¸æ“šï¼ˆCPA / CTR / CVR / CPMï¼‰
- ç‚ºä½•ã€Œç›¸å°æ–¼èª°ã€è€Œåšæ­¤åˆ¤æ–·
- æ˜ç¢ºå‹•ä½œæŒ‡ä»¤ï¼ˆé—œé–‰ / ç§»å‡º / ç¨ç«‹ / ä¿ç•™ï¼‰

---

## 3ï¸âƒ£ è¡Œå‹•ç‰ˆå¾…è¾¦æ¸…å–®ï¼ˆçµ¦äººç›´æ¥ç…§åšï¼‰
è«‹è¼¸å‡ºä¸€ä»½å¯ç›´æ¥åŸ·è¡Œçš„æ¸…å–®ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

- [æš«åœ] Ad Xï¼ˆåŸå› ï¼šC é¡ï¼Œåœ¨æ­¤çµ„åˆæ‹–ç´¯ CPAï¼‰
- [æ‹†åˆ†] Ad Y â†’ æ–° AdSetï¼ˆåŸå› ï¼šE é¡ï¼Œå…·ç¨ç«‹æ“´é‡æ½›åŠ›ï¼‰
- [ä¿ç•™ä¸å‹•] AdSet Zï¼ˆåŸå› ï¼šF é¡ï¼Œç©©å®šåŸºæœ¬ç›¤ï¼‰

---

# âš ï¸ é‡è¦æé†’
- è‹¥è³‡æ–™ä¸è¶³ï¼Œè«‹èªªæ˜ã€Œå“ªä¸€æ®µåˆ¤æ–·é¢¨éšªè¼ƒé«˜ã€
- è‹¥æŸç´ æä¸æ˜¯çˆ›ï¼Œè€Œæ˜¯ã€Œæ”¾éŒ¯åœ°æ–¹ã€ï¼Œè«‹æ˜ç¢ºæŒ‡å‡º
- è«‹é¿å…æ¨¡ç³Šå»ºè­°ï¼ˆå¦‚ï¼šå¯è€ƒæ…®ã€ä¹Ÿè¨±ã€å¯èƒ½ï¼‰

ä½ ç¾åœ¨æ˜¯è£åˆ¤ï¼Œä¸æ˜¯æ—ç™½ã€‚

"""

# ==========================================
# 1. åŸºç¤è¨­å®šèˆ‡å­—å‹è™•ç†
# ==========================================
st.set_page_config(page_title="å»£å‘Šæˆæ•ˆå…¨èƒ½åˆ†æ v6.3 (Gemini 2.5 Pro + CPM)", layout="wide")

@st.cache_resource
def get_chinese_font():
    font_path = "NotoSansCJKtc-Regular.otf"
    url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/TraditionalChinese/NotoSansCJKtc-Regular.otf"
    if not os.path.exists(font_path):
        try:
            with st.spinner('æ­£åœ¨ä¸‹è¼‰ä¸­æ–‡å­—å‹ (é¦–æ¬¡åŸ·è¡Œéœ€æ™‚è¼ƒä¹…)...'):
                urllib.request.urlretrieve(url, font_path)
        except Exception:
            return None
    return fm.FontProperties(fname=font_path)

font_prop = get_chinese_font()

# ==========================================
# 2. æ ¸å¿ƒè¨ˆç®—é‚è¼¯
# ==========================================

def clean_ad_name(name):
    return re.sub(r' - è¤‡æœ¬.*$', '', str(name)).strip()

def create_summary_row(df, metric_cols):
    """
    metric_cols: dict
      key: æŒ‡æ¨™åç¨±ï¼Œå¦‚ 'CPA (TWD)'
      val: (numerator_col, denominator_col, multiplier)
      multiplier: 1 (ç´”æ¯”å€¼), 100 (ç™¾åˆ†æ¯”), 1000 (æ¯åƒæ¬¡ï¼Œå¦‚ CPM)
    """
    summary_dict = {}
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        summary_dict[col] = df[col].sum()
        
    for metric, (num, denom, multiplier) in metric_cols.items():
        total_num = summary_dict.get(num, 0)
        total_denom = summary_dict.get(denom, 0)
        if total_denom > 0:
            val = (total_num / total_denom) * multiplier
            summary_dict[metric] = round(val, 2)
        else:
            summary_dict[metric] = 0

    non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns
    if len(non_numeric_cols) > 0:
        summary_dict[non_numeric_cols[0]] = 'å…¨å¸³æˆ¶å¹³å‡'
        for col in non_numeric_cols[1:]:
            summary_dict[col] = '-'
    return pd.DataFrame([summary_dict])

def calculate_consolidated_metrics(df_group, conv_col):
    """
    å°ä»»ä¸€å±¤ç´šï¼ˆCampaign / AdSet / Ad / Detailï¼‰ï¼š
    - å…ˆ sum èŠ±è²» / æ›å…‰ / é»æ“Š / è½‰æ›
    - å†ç”¨ aggregated æ•¸å­—ç®— CPA / CTR / CVR / CPM
    """
    df_metrics = df_group.agg({
        'èŠ±è²»é‡‘é¡ (TWD)': 'sum',
        conv_col: 'sum',
        'é€£çµé»æ“Šæ¬¡æ•¸': 'sum',
        'æ›å…‰æ¬¡æ•¸': 'sum'
    }).reset_index()

    df_metrics = df_metrics[df_metrics['èŠ±è²»é‡‘é¡ (TWD)'] > 0]

    # CPA / CTR / CVR / CPM
    df_metrics['CPA (TWD)'] = df_metrics.apply(
        lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x[conv_col] if x[conv_col] > 0 else 0, axis=1
    )
    df_metrics['CTR (%)'] = df_metrics.apply(
        lambda x: (x['é€£çµé»æ“Šæ¬¡æ•¸'] / x['æ›å…‰æ¬¡æ•¸']) * 100 if x['æ›å…‰æ¬¡æ•¸'] > 0 else 0, axis=1
    )
    df_metrics['CVR (%)'] = df_metrics.apply(
        lambda x: (x[conv_col] / x['é€£çµé»æ“Šæ¬¡æ•¸']) * 100 if x['é€£çµé»æ“Šæ¬¡æ•¸'] > 0 else 0, axis=1
    )
    df_metrics['CPM (TWD)'] = df_metrics.apply(
        lambda x: (x['èŠ±è²»é‡‘é¡ (TWD)'] / x['æ›å…‰æ¬¡æ•¸']) * 1000 if x['æ›å…‰æ¬¡æ•¸'] > 0 else 0, axis=1
    )
    
    df_metrics = df_metrics.round(2).sort_values(by='èŠ±è²»é‡‘é¡ (TWD)', ascending=False)

    metric_config = {
        'CPA (TWD)': ('èŠ±è²»é‡‘é¡ (TWD)', conv_col, 1),
        'CTR (%)': ('é€£çµé»æ“Šæ¬¡æ•¸', 'æ›å…‰æ¬¡æ•¸', 100),
        'CVR (%)': (conv_col, 'é€£çµé»æ“Šæ¬¡æ•¸', 100),
        'CPM (TWD)': ('èŠ±è²»é‡‘é¡ (TWD)', 'æ›å…‰æ¬¡æ•¸', 1000)
    }
    summary_row = create_summary_row(df_metrics, metric_config)
    
    if not df_metrics.empty:
        return pd.concat([df_metrics, summary_row], ignore_index=True)
    else:
        return df_metrics

def collect_period_results(df, period_name_short, conv_col):
    df['å»£å‘Šåç¨±_clean'] = df['å»£å‘Šåç¨±'].apply(clean_ad_name)
    results = []
    
    # 0. è©³ç´°å±¤ç´šï¼šæ´»å‹• + çµ„åˆ + å»£å‘Š
    results.append((
        f'{period_name_short}_Detail_è©³ç´°(çµ„åˆ+å»£å‘Š)', 
        calculate_consolidated_metrics(df.groupby(['è¡ŒéŠ·æ´»å‹•åç¨±', 'å»£å‘Šçµ„åˆåç¨±', 'å»£å‘Šåç¨±']), conv_col)
    ))
    # 1. å»£å‘Šå±¤ç´š
    results.append(
        (f'{period_name_short}_Ad_å»£å‘Š',
         calculate_consolidated_metrics(df.groupby('å»£å‘Šåç¨±_clean'), conv_col))
    )
    # 2. å»£å‘Šçµ„åˆå±¤ç´šï¼ˆé€™è£¡ä¹Ÿæœƒæœ‰ CPMï¼‰
    results.append(
        (f'{period_name_short}_AdSet_å»£å‘Šçµ„åˆ',
         calculate_consolidated_metrics(df.groupby(['è¡ŒéŠ·æ´»å‹•åç¨±', 'å»£å‘Šçµ„åˆåç¨±']), conv_col))
    )
    # 3. è¡ŒéŠ·æ´»å‹•å±¤ç´š
    results.append(
        (f'{period_name_short}_Campaign_è¡ŒéŠ·æ´»å‹•',
         calculate_consolidated_metrics(df.groupby('è¡ŒéŠ·æ´»å‹•åç¨±'), conv_col))
    )
    
    return results

# ==========================================
# 3. ç•°å¸¸åµæ¸¬èˆ‡è¶¨å‹¢åˆ†æé‚è¼¯
# ==========================================
def check_daily_anomalies(df_p1, df_p7, level_name='è¡ŒéŠ·æ´»å‹•åç¨±'):
    p1 = df_p1[df_p1[level_name] != 'å…¨å¸³æˆ¶å¹³å‡'].copy()
    p7 = df_p7[df_p7[level_name] != 'å…¨å¸³æˆ¶å¹³å‡'].copy()
    
    if p1.empty or p7.empty:
        return pd.DataFrame()

    merged = pd.merge(p1, p7, on=level_name, suffixes=('_P1', '_P7'), how='inner')
    alerts = []
    
    for _, row in merged.iterrows():
        if row['èŠ±è²»é‡‘é¡ (TWD)_P1'] < 200: 
            continue 

        name = row[level_name]
        cpa_p1, cpa_p7 = row['CPA (TWD)_P1'], row['CPA (TWD)_P7']
        ctr_p1, ctr_p7 = row['CTR (%)_P1'], row['CTR (%)_P7']
        spend_p1 = row['èŠ±è²»é‡‘é¡ (TWD)_P1']

        if cpa_p7 > 0 and cpa_p1 > cpa_p7 * 1.3:
            diff = int(((cpa_p1 - cpa_p7) / cpa_p7) * 100)
            alerts.append({
                'å±¤ç´š': level_name,
                'åç¨±': name,
                'é¡å‹': 'ğŸ”´ CPA æš´æ¼²', 
                'æ•¸æ“šå°æ¯”': f"æ˜¨${cpa_p1:.0f} vs å‡${cpa_p7:.0f} (ğŸ”º{diff}%)",
                'å»ºè­°': 'æª¢æŸ¥ç«¶åƒ¹æˆ–å—çœ¾'
            })
            
        if ctr_p7 > 0 and ctr_p1 < ctr_p7 * 0.8:
            diff = int(((ctr_p7 - ctr_p1) / ctr_p7) * 100)
            alerts.append({
                'å±¤ç´š': level_name,
                'åç¨±': name,
                'é¡å‹': 'ğŸ“‰ CTR é©Ÿé™', 
                'æ•¸æ“šå°æ¯”': f"æ˜¨{ctr_p1}% vs å‡{ctr_p7}% (ğŸ”»{diff}%)",
                'å»ºè­°': 'ç´ æç–²ä¹/æ›´æ›ç´ æ'
            })
            
        if cpa_p1 == 0 and spend_p1 > 500:
             alerts.append({
                 'å±¤ç´š': level_name,
                 'åç¨±': name,
                 'é¡å‹': 'ğŸ›‘ é«˜èŠ±è²»0è½‰æ›', 
                 'æ•¸æ“šå°æ¯”': f"æ˜¨èŠ±è²» ${spend_p1:.0f}",
                 'å»ºè­°': 'æª¢æŸ¥è½åœ°é /è¨­å®š'
             })

    return pd.DataFrame(alerts)

def check_weekly_trends(df_p7, df_pp7, level_name='è¡ŒéŠ·æ´»å‹•åç¨±'):
    curr = df_p7[df_p7[level_name] != 'å…¨å¸³æˆ¶å¹³å‡'].copy()
    prev = df_pp7[df_pp7[level_name] != 'å…¨å¸³æˆ¶å¹³å‡'].copy()
    
    if curr.empty or prev.empty:
        return pd.DataFrame()
    
    merged = pd.merge(curr, prev, on=level_name, suffixes=('_This', '_Last'), how='inner')
    trends = []
    
    for _, row in merged.iterrows():
        if row['èŠ±è²»é‡‘é¡ (TWD)_This'] < 1000: 
            continue
        
        name = row[level_name]
        cpa_this, cpa_last = row['CPA (TWD)_This'], row['CPA (TWD)_Last']
        ctr_this, ctr_last = row['CTR (%)_This'], row['CTR (%)_Last']
        spend_this, spend_last = row['èŠ±è²»é‡‘é¡ (TWD)_This'], row['èŠ±è²»é‡‘é¡ (TWD)_Last']
        
        if cpa_last > 0 and cpa_this > cpa_last * 1.2:
            diff = int(((cpa_this - cpa_last) / cpa_last) * 100)
            trends.append({
                'å±¤ç´š': level_name,
                'åç¨±': name,
                'ç‹€æ…‹': 'âš ï¸ æˆæœ¬æƒ¡åŒ–',
                'æ•¸æ“šè®ŠåŒ–': f"${cpa_this:.0f} (vs ${cpa_last:.0f})",
                'è®ŠåŒ–å¹…åº¦': f"ğŸ”º +{diff}%",
                'è¨ºæ–·': 'ç«¶çˆ­åŠ åŠ‡æˆ–è½‰æ›ç‡ä¸‹é™'
            })
            
        if ctr_last > 0 and ctr_this < ctr_last * 0.85:
            diff = int(((ctr_last - ctr_this) / ctr_this) * 100) if ctr_this > 0 else 100
            trends.append({
                'å±¤ç´š': level_name,
                'åç¨±': name,
                'ç‹€æ…‹': 'ğŸ“‰ CTR è¡°é€€',
                'æ•¸æ“šè®ŠåŒ–': f"{ctr_this}% (vs {ctr_last}%)",
                'è®ŠåŒ–å¹…åº¦': f"ğŸ”» -{diff}%",
                'è¨ºæ–·': 'ç´ æé–‹å§‹è€åŒ–'
            })

        if spend_last > 0 and spend_this > spend_last * 1.2:
            if cpa_last > 0 and cpa_this > cpa_last * 1.1:
                trends.append({
                    'å±¤ç´š': level_name,
                    'åç¨±': name,
                    'ç‹€æ…‹': 'ğŸ’¸ æ“´é‡æ•ˆç‡å·®',
                    'æ•¸æ“šè®ŠåŒ–': f"èŠ±è²»å¢è‡³ ${spend_this:,.0f}",
                    'è®ŠåŒ–å¹…åº¦': f"CPA äº¦æ¼²",
                    'è¨ºæ–·': 'é‚Šéš›æ•ˆæ‡‰éæ¸›ï¼Œå»ºè­°æš«åœåŠ ç¢¼'
                })

    return pd.DataFrame(trends)

def get_trend_data_excel(df_p30d, conv_col):
    trend_df = df_p30d.copy()
    acc_daily = trend_df.groupby(['å¤©æ•¸']).agg({
        'èŠ±è²»é‡‘é¡ (TWD)': 'sum',
        conv_col: 'sum',
        'é€£çµé»æ“Šæ¬¡æ•¸': 'sum',
        'æ›å…‰æ¬¡æ•¸': 'sum'
    }).reset_index()
    acc_daily['è¡ŒéŠ·æ´»å‹•åç¨±'] = 'ğŸ† æ•´é«”å¸³æˆ¶ (Account Overall)'
    final_trend = acc_daily[acc_daily['èŠ±è²»é‡‘é¡ (TWD)'] > 0]
    final_trend['CPA (TWD)'] = final_trend.apply(
        lambda x: x['èŠ±è²»é‡‘é¡ (TWD)'] / x[conv_col] if x[conv_col] > 0 else 0,
        axis=1
    )
    final_trend['CPM (TWD)'] = final_trend.apply(
        lambda x: (x['èŠ±è²»é‡‘é¡ (TWD)'] / x['æ›å…‰æ¬¡æ•¸']) * 1000 if x['æ›å…‰æ¬¡æ•¸'] > 0 else 0,
        axis=1
    )
    final_trend['å¤©æ•¸'] = final_trend['å¤©æ•¸'].dt.strftime('%Y-%m-%d')
    return final_trend.round(2)

def build_cpm_change_table(p7_camp_df, pp7_camp_df, p30_camp_df):
    """
    å»ºç«‹è¡ŒéŠ·æ´»å‹•å±¤ç´šçš„ CPM è®ŠåŒ–è¡¨ï¼šP7D / PP7D / P30D
    """
    def prep(df, suffix):
        if df is None or df.empty:
            return pd.DataFrame(columns=['è¡ŒéŠ·æ´»å‹•åç¨±', f'CPM_{suffix}', f'èŠ±è²»é‡‘é¡_{suffix}', f'æ›å…‰æ¬¡æ•¸_{suffix}'])
        tmp = df.copy()
        cols_keep = ['è¡ŒéŠ·æ´»å‹•åç¨±', 'CPM (TWD)', 'èŠ±è²»é‡‘é¡ (TWD)', 'æ›å…‰æ¬¡æ•¸']
        cols_exist = [c for c in cols_keep if c in tmp.columns]
        tmp = tmp[cols_exist]
        tmp = tmp[tmp['è¡ŒéŠ·æ´»å‹•åç¨±'].notna()]
        tmp = tmp.rename(columns={
            'CPM (TWD)': f'CPM_{suffix}',
            'èŠ±è²»é‡‘é¡ (TWD)': f'èŠ±è²»é‡‘é¡_{suffix}',
            'æ›å…‰æ¬¡æ•¸': f'æ›å…‰æ¬¡æ•¸_{suffix}'
        })
        return tmp

    p7 = prep(p7_camp_df, 'P7D')
    pp7 = prep(pp7_camp_df, 'PP7D')
    p30 = prep(p30_camp_df, 'P30D')

    merged = p7.merge(pp7, on='è¡ŒéŠ·æ´»å‹•åç¨±', how='outer').merge(p30, on='è¡ŒéŠ·æ´»å‹•åç¨±', how='outer')
    if merged.empty:
        return merged

    for c in ['CPM_P7D', 'CPM_PP7D', 'CPM_P30D',
              'èŠ±è²»é‡‘é¡_P7D', 'èŠ±è²»é‡‘é¡_PP7D', 'èŠ±è²»é‡‘é¡_P30D',
              'æ›å…‰æ¬¡æ•¸_P7D', 'æ›å…‰æ¬¡æ•¸_PP7D', 'æ›å…‰æ¬¡æ•¸_P30D']:
        if c in merged.columns:
            merged[c] = merged[c].fillna(0)

    def pct_change(new, old):
        if old == 0:
            return None
        return round((new - old) / old * 100, 2)

    merged['CPM_é€±ç’°æ¯”è®ŠåŒ–_vs_PP7D_(%)'] = merged.apply(
        lambda x: pct_change(x['CPM_P7D'], x['CPM_PP7D']), axis=1
    )
    merged['CPM_æœˆåº¦å°æ¯”_vs_P30D_(%)'] = merged.apply(
        lambda x: pct_change(x['CPM_P7D'], x['CPM_P30D']), axis=1
    )

    if 'èŠ±è²»é‡‘é¡_P7D' in merged.columns:
        merged = merged.sort_values('èŠ±è²»é‡‘é¡_P7D', ascending=False)

    return merged

# ==========================================
# 4. Excel åŒ¯å‡ºå‡½æ•¸ï¼ˆå« AI å›è¦†ï¼‰
# ==========================================
def to_excel_single_sheet_stacked(dfs_list, prompt_text, ai_response=None):
    engine = 'xlsxwriter' if HAS_XLSXWRITER else None
    if not engine:
        pass

    output = io.BytesIO()
    try:
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            workbook = writer.book
            sheet_name = 'ğŸ“˜_å®Œæ•´åˆ†æå ±å‘Š'
            ws = workbook.add_worksheet(sheet_name)
            writer.sheets[sheet_name] = ws
            
            fmt_prompt = workbook.add_format({
                'text_wrap': True, 'valign': 'top',
                'font_size': 10, 'bg_color': '#F0F2F6'
            })
            fmt_ai_response = workbook.add_format({
                'text_wrap': True, 'valign': 'top',
                'font_size': 11, 'bg_color': '#FFF8DC',
                'border': 1
            })
            fmt_header = workbook.add_format({
                'bold': True, 'font_size': 14,
                'font_color': '#0068C9'
            })
            fmt_table_header = workbook.add_format({
                'bold': True, 'bg_color': '#E6E6E6', 'border': 1
            })
            
            current_row = 0
            
            # 1. AI åˆ†æçµæœ
            if ai_response:
                ws.merge_range('A1:K1', "ğŸ¤– Gemini AI å»£å‘Šè¨ºæ–·å ±å‘Š (AI Analysis Report)", fmt_header)
                current_row += 1
                ai_lines = ai_response.count('\n') + (len(ai_response) // 50) + 2
                ws.merge_range(current_row, 0, current_row + ai_lines, 10, ai_response, fmt_ai_response)
                current_row += ai_lines + 2
            
            # 2. System Prompt
            ws.merge_range(current_row, 0, current_row, 8, "ğŸ› ï¸ ç³»çµ±åˆ†ææŒ‡ä»¤ (System Prompt Log)", fmt_header)
            current_row += 1
            prompt_lines = prompt_text.count('\n') + 3
            ws.merge_range(current_row, 0, current_row + prompt_lines, 10, prompt_text, fmt_prompt)
            current_row += prompt_lines + 2
            
            # 3. æ•¸æ“šè¡¨
            for title, df in dfs_list:
                ws.write(current_row, 0, f"ğŸ“Œ Table: {title}", fmt_header)
                current_row += 1
                df.to_excel(writer, sheet_name=sheet_name, startrow=current_row, index=False)
                for col_num, value in enumerate(df.columns.values):
                    ws.write(current_row, col_num, value, fmt_table_header)
                current_row += len(df) + 4
                
            ws.set_column('A:A', 40)
            ws.set_column('B:Z', 15)
    except Exception:
        return None
            
    output.seek(0)
    return output.getvalue()

# ==========================================
# 5. AI åˆ†æä¸²æ¥ï¼šè¼”åŠ©å‡½å¼ï¼ˆå¤šå±¤ç´šé¤µå…¥ï¼‰
# ==========================================
def safe_to_markdown(df):
    try:
        return df.to_markdown(index=False)
    except ImportError:
        return df.to_csv(sep='|', index=False)
    except Exception:
        return df.to_string(index=False)

def get_top_by_spend(df, n=20, min_spend=0):
    if df is None or df.empty:
        return df

    tmp = df.copy()

    for col in ['è¡ŒéŠ·æ´»å‹•åç¨±', 'å»£å‘Šåç¨±_clean']:
        if col in tmp.columns:
            tmp = tmp[tmp[col] != 'å…¨å¸³æˆ¶å¹³å‡']

    if 'èŠ±è²»é‡‘é¡ (TWD)' in tmp.columns:
        tmp = tmp[tmp['èŠ±è²»é‡‘é¡ (TWD)'] >= min_spend]
        tmp = tmp.sort_values('èŠ±è²»é‡‘é¡ (TWD)', ascending=False).head(n)

    return tmp

def call_gemini_analysis(
    api_key,
    alerts_daily,
    alerts_weekly,
    campaign_summary,
    adset_p7=None,
    ad_p7=None,
    trend_30d=None,
    cpm_change_table=None
):
    data_context = "\n\n# ğŸ“Š Account Data Summaryï¼ˆå¤šå±¤ç´šè¦–è§’ï¼‰\n"

    data_context += "\n## 1. Daily Alerts (P1D vs P7D Anomalies)\n"
    if alerts_daily is not None and not alerts_daily.empty:
        data_context += safe_to_markdown(alerts_daily)
    else:
        data_context += "No critical daily anomalies detected."

    data_context += "\n\n## 2. Weekly Trends (P7D vs PP7D Decline)\n"
    if alerts_weekly is not None and not alerts_weekly.empty:
        data_context += safe_to_markdown(alerts_weekly)
    else:
        data_context += "No significant weekly decline trends detected."

    data_context += "\n\n## 3. Current Week Campaign Performance (P7D)\n"
    if campaign_summary is not None and not campaign_summary.empty:
        top_campaigns = get_top_by_spend(campaign_summary, n=20, min_spend=0)
        data_context += safe_to_markdown(top_campaigns)
    else:
        data_context += "No campaign-level data available."

    if adset_p7 is not None and not adset_p7.empty:
        data_context += "\n\n## 4. P7D AdSet Performance (Top by Spend)\n"
        top_adsets = get_top_by_spend(adset_p7, n=30, min_spend=500)
        if top_adsets is not None and not top_adsets.empty:
            data_context += safe_to_markdown(top_adsets)

    if ad_p7 is not None and not ad_p7.empty:
        data_context += "\n\n## 5. P7D Ad Performance (Top by Spend)\n"
        top_ads = get_top_by_spend(ad_p7, n=50, min_spend=300)
        if top_ads is not None and not top_ads.empty:
            data_context += safe_to_markdown(top_ads)

    if trend_30d is not None and not trend_30d.empty:
        data_context += "\n\n## 6. 30D Account Daily Trend (Account Overall)\n"
        data_context += safe_to_markdown(trend_30d)

    if cpm_change_table is not None and not cpm_change_table.empty:
        data_context += "\n\n## 7. CPM Change Table (P7D vs PP7D vs P30D, Campaign Level)\n"
        data_context += safe_to_markdown(cpm_change_table)

    full_prompt = (
        AI_CONSULTANT_PROMPT
        + data_context
        + "\n\n# User Request: è«‹æ ¹æ“šä¸Šè¿°å¤šå±¤ç´šæ•¸æ“šï¼Œç”¢ç”Ÿä¸€ä»½å»£å‘Šå„ªåŒ–è¨ºæ–·å ±å‘Šï¼Œä¸¦æ˜ç¢ºæŒ‡å‡ºï¼šæ´»å‹• / AdSet / å»£å‘Šå±¤ç´šçš„èª¿æ•´å»ºè­°ï¼Œç‰¹åˆ¥èªªæ˜ CPM è®ŠåŒ–å¦‚ä½•å½±éŸ¿ CPA èˆ‡ CPCã€‚"
    )

    with st.spinner('ğŸ¤– AI æ­£åœ¨åˆ†ææ•¸æ“šä¸­... (é€™å¯èƒ½éœ€è¦ 10â€“20 ç§’)'):
        try:
            if HAS_GENAI:
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel('gemini-2.5-pro')
                response = model.generate_content(full_prompt)
                return response.text if hasattr(response, "text") else str(response)

            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent?key={api_key}"
            headers = {'Content-Type': 'application/json'}
            data = {
                "contents": [{
                    "parts": [{"text": full_prompt}]
                }]
            }
            response = requests.post(url, headers=headers, json=data)

            if response.status_code == 200:
                result_json = response.json()
                try:
                    return result_json['candidates'][0]['content']['parts'][0]['text']
                except (KeyError, IndexError):
                    return f"âš ï¸ API å›å‚³æ ¼å¼ä¸å¦‚é æœŸ: {str(result_json)}"
            else:
                return f"âš ï¸ API é€£ç·šéŒ¯èª¤ ({response.status_code}): {response.text}"

        except Exception as e:
            return f"âŒ ç³»çµ±ç™¼ç”ŸéŒ¯èª¤: {str(e)}\nè«‹æª¢æŸ¥ API Key æ˜¯å¦æ­£ç¢ºï¼Œæˆ–è©² Key æ˜¯å¦æœ‰æ¬Šé™å­˜å– 2.5 Pro æ¨¡å‹ã€‚"

# ==========================================
# 6. ä¸»ç¨‹å¼ UI
# ==========================================
st.title("ğŸ“Š å»£å‘Šæˆæ•ˆå…¨èƒ½åˆ†æ v6.3 (Gemini 2.5 Pro + CPM)")

if not HAS_GENAI:
    st.warning("â„¹ï¸ æç¤ºï¼šæœªåµæ¸¬åˆ° `google-generativeai` å¥—ä»¶ã€‚ç³»çµ±å°‡è‡ªå‹•åˆ‡æ›ç‚º **REST API å…¼å®¹æ¨¡å¼** (åªéœ€ API Key å³å¯é‹ä½œ)ã€‚")
if not HAS_XLSXWRITER:
    st.warning("âš ï¸ è­¦å‘Šï¼šæœªåµæ¸¬åˆ° `xlsxwriter` å¥—ä»¶ã€‚Excel åŒ¯å‡ºåŠŸèƒ½å¯èƒ½æœƒå¤±æ•ˆã€‚")

if 'gemini_result' not in st.session_state:
    st.session_state['gemini_result'] = None

uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ CSV å ±è¡¨æª”æ¡ˆ", type=['csv'])

if uploaded_file is not None:
    try:
        # 1. è®€å–èˆ‡æ¬„ä½åµæ¸¬
        try:
            df = pd.read_csv(uploaded_file, encoding='utf-8')
        except UnicodeDecodeError:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding='cp950')
        except Exception as e:
            st.error(f"æª”æ¡ˆè®€å–æœªçŸ¥çš„éŒ¯èª¤: {e}")
            st.stop()

        df.columns = df.columns.str.strip()
        all_columns = df.columns.tolist()
        
        # å´é‚Šæ¬„è¨­å®š
        with st.sidebar:
            st.header("âš™ï¸ åˆ†æè¨­å®š")
            
            st.subheader("ğŸ¤– AI åˆ†æè¨­å®š")
            gemini_api_key = st.text_input("Gemini API Key", type="password", placeholder="è¼¸å…¥ Key ä»¥å•Ÿç”¨ AI åˆ†æ")
            st.caption("[å–å¾— Google AI Studio Key](https://aistudio.google.com/app/apikey)")
            st.divider()
            
            suggested_idx = 0
            for idx, col in enumerate(all_columns):
                c_low = col.lower()
                if 'æˆæœ¬' in col or 'cost' in c_low: 
                    continue
                if ('free' in c_low and 'course' in c_low):
                    suggested_idx = idx
                    break
                if 'è³¼è²·' in col or 'purchase' in c_low:
                    suggested_idx = idx
                    break
                if 'è½‰æ›' in col:
                    suggested_idx = idx
                    break
                
            conversion_col = st.selectbox("ğŸ¯ ç›®æ¨™è½‰æ›æ¬„ä½:", options=all_columns, index=suggested_idx)
            
            def find_col(opts, default):
                for opt in opts:
                    for col in all_columns:
                        if opt in col:
                            return col
                return default

            spend_col = find_col(['èŠ±è²»é‡‘é¡ (TWD)', 'èŠ±è²»', 'é‡‘é¡'], 'èŠ±è²»é‡‘é¡ (TWD)')
            clicks_col = find_col(['é€£çµé»æ“Šæ¬¡æ•¸', 'é€£çµé»æ“Š'], 'é€£çµé»æ“Šæ¬¡æ•¸')
            impressions_col = find_col(['æ›å…‰æ¬¡æ•¸', 'æ›å…‰'], 'æ›å…‰æ¬¡æ•¸')

        # 2. æ•¸æ“šæ¸…æ´—
        cols_to_numeric = [spend_col, clicks_col, impressions_col, conversion_col]
        for col in cols_to_numeric:
            if col in df.columns:
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str).str.replace(',', '', regex=False)
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

        if 'å¤©æ•¸' not in df.columns:
            st.error("éŒ¯èª¤ï¼šCSV æª”æ¡ˆä¸­æ‰¾ä¸åˆ°ã€Œå¤©æ•¸ã€æ¬„ä½ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼ã€‚")
            st.stop()

        df['å¤©æ•¸'] = pd.to_datetime(df['å¤©æ•¸'], errors='coerce')
        df = df.dropna(subset=['å¤©æ•¸'])

        df_std = df.rename(columns={
            spend_col: 'èŠ±è²»é‡‘é¡ (TWD)',
            clicks_col: 'é€£çµé»æ“Šæ¬¡æ•¸',
            impressions_col: 'æ›å…‰æ¬¡æ•¸'
        })
        
        # 3. æ—¥æœŸå€é–“èˆ‡è³‡æ–™åˆ†çµ„
        if df_std.empty:
            st.error("éŒ¯èª¤ï¼šè³‡æ–™ç¶“éæ¸…æ´—å¾Œç‚ºç©ºï¼Œè«‹æª¢æŸ¥åŸå§‹æª”æ¡ˆæ˜¯å¦åŒ…å«æœ‰æ•ˆçš„æ—¥æœŸèˆ‡æ•¸æ“šã€‚")
            st.stop()

        max_date = df_std['å¤©æ•¸'].max().normalize()
        today = max_date + timedelta(days=1)
        
        p1d_start = max_date
        df_p1d = df_std[df_std['å¤©æ•¸'] == p1d_start].copy()
        
        p7d_start = today - timedelta(days=7)
        p7d_end = today - timedelta(days=1)
        pp7d_start = p7d_start - timedelta(days=7)
        pp7d_end = p7d_start - timedelta(days=1)
        p30d_start = today - timedelta(days=30)
        p30d_end = today - timedelta(days=1)
        
        df_p7d = df_std[(df_std['å¤©æ•¸'] >= p7d_start) & (df_std['å¤©æ•¸'] <= p7d_end)].copy()
        df_pp7d = df_std[(df_std['å¤©æ•¸'] >= pp7d_start) & (df_std['å¤©æ•¸'] <= pp7d_end)].copy()
        df_p30d = df_std[(df_std['å¤©æ•¸'] >= p30d_start) & (df_std['å¤©æ•¸'] <= p30d_end)].copy()
        
        # å„å€é–“ Campaign å±¤ç´š
        res_p1d_camp = calculate_consolidated_metrics(df_p1d.groupby('è¡ŒéŠ·æ´»å‹•åç¨±'), conversion_col)
        res_p7d_camp = calculate_consolidated_metrics(df_p7d.groupby('è¡ŒéŠ·æ´»å‹•åç¨±'), conversion_col)
        res_pp7d_camp = calculate_consolidated_metrics(df_pp7d.groupby('è¡ŒéŠ·æ´»å‹•åç¨±'), conversion_col)
        
        # è­¦ç¤ºèˆ‡é€±è¶¨å‹¢
        alerts_daily = check_daily_anomalies(res_p1d_camp, res_p7d_camp, 'è¡ŒéŠ·æ´»å‹•åç¨±')
        alerts_weekly = check_weekly_trends(res_p7d_camp, res_pp7d_camp, 'è¡ŒéŠ·æ´»å‹•åç¨±')

        # å„å€é–“å¤šå±¤ç´šåŒ¯ç¸½
        res_p1 = collect_period_results(df_p1d, 'P1D', conversion_col)
        res_p7 = collect_period_results(df_p7d, 'P7D', conversion_col)
        res_pp7 = collect_period_results(df_pp7d, 'PP7D', conversion_col)
        res_p30 = collect_period_results(df_p30d, 'P30D', conversion_col)

        # P7D å¤šå±¤ç´š DataFrame çµ¦ AI ç”¨
        p7_detail_df = res_p7[0][1]
        p7_ad_df     = res_p7[1][1]
        p7_adset_df  = res_p7[2][1]
        p7_camp_df   = res_p7[3][1]

        # P30D è¡ŒéŠ·æ´»å‹•å±¤ç´šï¼Œç”¨æ–¼ CPM è®ŠåŒ–è¡¨
        p30_camp_df = res_p30[3][1] if len(res_p30) >= 4 else None

        # 30 æ—¥å¸³æˆ¶è¶¨å‹¢ DataFrame
        trend_30d_df = get_trend_data_excel(df_p30d, conversion_col)

        # CPM è®ŠåŒ–è¡¨
        cpm_change_df = build_cpm_change_table(
            p7_camp_df,
            res_pp7d_camp,
            p30_camp_df
        )

        # --- UI Tabs ---
        tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ æˆ°æƒ…å®¤ & é›™é‡ç›£æ§", "ğŸ“‘ è©³ç´°æ•¸æ“šè¡¨ (AdSet+Ad)", "ğŸ¤– AI æ·±åº¦è¨ºæ–· (Gemini)"])
        
        # ========== Tab 1ï¼šæˆ°æƒ…å®¤ ==========
        with tab1:
            col_a, col_b = st.columns(2)
            with col_a:
                st.subheader("ğŸš¨ P1D ç·Šæ€¥è­¦ç¤º (æ˜¨æ—¥ vs å‡å€¼)")
                if not alerts_daily.empty:
                    st.dataframe(alerts_daily, hide_index=True, use_container_width=True)
                else:
                    st.success("æ˜¨æ—¥è¡¨ç¾å¹³ç©© (ç„¡ CPAæš´æ¼² / CTRé©Ÿé™)")
            
            with col_b:
                st.subheader("ğŸ“‰ P7D é€±ç’°æ¯”è¡°é€€ (æœ¬é€± vs ä¸Šé€±)")
                if not alerts_weekly.empty:
                    st.dataframe(alerts_weekly, hide_index=True, use_container_width=True)
                else:
                    st.info("æœ¬é€±ç„¡é¡¯è‘—è¡°é€€é …ç›® (CPAèˆ‡CTRçš†ç©©å®š)")

            st.divider()
            # 30æ—¥æ¦‚æ³
            total_spend = df_p30d['èŠ±è²»é‡‘é¡ (TWD)'].sum()
            total_conv = df_p30d[conversion_col].sum()
            total_impr = df_p30d['æ›å…‰æ¬¡æ•¸'].sum()
            cpa_30d = total_spend / total_conv if total_conv > 0 else 0
            cpm_30d = (total_spend / total_impr * 1000) if total_impr > 0 else 0
            
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("è¿‘30æ—¥ç¸½èŠ±è²»", f"${total_spend:,.0f}")
            c2.metric("è¿‘30æ—¥ç¸½è½‰æ›", f"{total_conv:,.0f}")
            c3.metric("è¿‘30æ—¥å¹³å‡ CPA", f"${cpa_30d:,.0f}")
            c4.metric("è¿‘30æ—¥å¹³å‡ CPM", f"${cpm_30d:,.0f}")

            # è¶¨å‹¢åœ–ï¼šèŠ±è²» vs è½‰æ›
            daily = df_p30d.groupby('å¤©æ•¸')[['èŠ±è²»é‡‘é¡ (TWD)', conversion_col, 'é€£çµé»æ“Šæ¬¡æ•¸', 'æ›å…‰æ¬¡æ•¸']].sum().reset_index()
            daily['æ—¥æœŸstr'] = daily['å¤©æ•¸'].dt.strftime('%m-%d')
            
            fig, ax1 = plt.subplots(figsize=(12, 5))
            ax2 = ax1.twinx()
            ax1.bar(daily['æ—¥æœŸstr'], daily['èŠ±è²»é‡‘é¡ (TWD)'], alpha=0.6, label='èŠ±è²»')
            ax2.plot(daily['æ—¥æœŸstr'], daily[conversion_col], marker='o', label='è½‰æ›æ•¸', linewidth=2)
            ax1.set_xlabel('æ—¥æœŸ', fontproperties=font_prop)
            ax1.set_ylabel('èŠ±è²» (TWD)', fontproperties=font_prop)
            ax2.set_ylabel('è½‰æ›æ•¸', fontproperties=font_prop)
            if font_prop:
                for label in ax1.get_xticklabels():
                    label.set_fontproperties(font_prop)
            st.pyplot(fig)

            st.divider()
            st.subheader("ğŸ’° CPM è®ŠåŒ–æ¦‚æ³ï¼ˆè¡ŒéŠ·æ´»å‹•å±¤ç´šï¼šP7D / PP7D / P30Dï¼‰")
            if cpm_change_df is not None and not cpm_change_df.empty:
                st.dataframe(cpm_change_df, use_container_width=True)
            else:
                st.info("ç›®å‰ç„¡æ³•ç”¢ç”Ÿ CPM è®ŠåŒ–è¡¨ï¼ˆå¯èƒ½æ˜¯è³‡æ–™ä¸è¶³æˆ–æ¬„ä½ä¸å®Œæ•´ï¼‰ã€‚")

        # ========== Tab 2ï¼šè©³ç´°æ•¸æ“šè¡¨ ==========
        with tab2:
            st.markdown("### ğŸ” å„å€é–“è©³ç´°æ•¸æ“š (è¡ŒéŠ·æ´»å‹• > å»£å‘Šçµ„åˆ > å»£å‘Š)")
            t_p1, t_p7, t_pp7, t_p30 = st.tabs(["P1D (æ˜¨æ—¥)", "P7D (æœ¬é€±)", "PP7D (ä¸Šé€±)", "P30D (æœˆå ±)"])
            
            def render_data_tab(results_list, unique_key):
                st.info("ğŸ’¡ ä¸‹è¡¨ç‚ºã€Œè©³ç´°å±¤ç´šã€ï¼Œå¯çœ‹åˆ°æ¯å€‹ è¡ŒéŠ·æ´»å‹• > å»£å‘Šçµ„åˆ > å»£å‘Š çš„è¡¨ç¾ï¼ˆå« CPA / CTR / CVR / CPMï¼‰ã€‚")
                st.dataframe(results_list[0][1], use_container_width=True)
                
                with st.expander("æŸ¥çœ‹å…¶ä»–åŒ¯ç¸½å±¤ç´š (è¡ŒéŠ·æ´»å‹• / å»£å‘Šçµ„åˆ / å»£å‘Šæ•´é«”)"):
                    view_mode = st.radio(
                        "é¸æ“‡å…¶ä»–æª¢è¦–å±¤ç´š:", 
                        ["è¡ŒéŠ·æ´»å‹• (Campaign)", "å»£å‘Šçµ„åˆ (AdSet)", "å»£å‘Š (Ad)"],
                        horizontal=True,
                        key=unique_key
                    )
                    if view_mode == "è¡ŒéŠ·æ´»å‹• (Campaign)":
                        st.dataframe(results_list[3][1], use_container_width=True)
                    elif view_mode == "å»£å‘Šçµ„åˆ (AdSet)":
                        st.dataframe(results_list[2][1], use_container_width=True)
                    elif view_mode == "å»£å‘Š (Ad)":
                        st.dataframe(results_list[1][1], use_container_width=True)

            with t_p1:
                render_data_tab(res_p1, "radio_p1")
            with t_p7:
                render_data_tab(res_p7, "radio_p7")
            with t_pp7:
                render_data_tab(res_pp7, "radio_pp7")
            with t_p30:
                render_data_tab(res_p30, "radio_p30")

        # ========== Tab 3ï¼šAI æ·±åº¦è¨ºæ–· ==========
        with tab3:
            st.header("ğŸ¤– Gemini AI å»£å‘Šæˆæ•ˆè¨ºæ–·")
            st.markdown("""
AI å°‡ä¾ç…§ã€Œå¸³æˆ¶å±¤ç´š â†’ è¡ŒéŠ·æ´»å‹• â†’ AdSet â†’ å»£å‘Š â†’ 30 æ—¥è¶¨å‹¢ â†’ CPM è®ŠåŒ–ã€çš„å¤šå±¤ç´šæ•¸æ“šï¼Œ
è‡ªå‹•ç”¢ç”Ÿå„ªåŒ–è¨ºæ–·å ±å‘Šèˆ‡å¯åŸ·è¡Œå»ºè­°ï¼Œä¸¦ç‰¹åˆ¥èªªæ˜ CPM è®ŠåŒ–å° CPA / CPC çš„å½±éŸ¿ã€‚
            """)
            
            col_ai_btn, _ = st.columns([1, 2])
            with col_ai_btn:
                run_ai = st.button("ğŸš€ é–‹å§‹ AI æ™ºèƒ½åˆ†æ", type="primary")
            
            if run_ai:
                if not gemini_api_key:
                    st.warning("âš ï¸ è«‹å…ˆæ–¼å·¦å´å´é‚Šæ¬„è¼¸å…¥ Gemini API Key")
                else:
                    analysis_result = call_gemini_analysis(
                        api_key=gemini_api_key,
                        alerts_daily=alerts_daily,
                        alerts_weekly=alerts_weekly,
                        campaign_summary=p7_camp_df,
                        adset_p7=p7_adset_df,
                        ad_p7=p7_ad_df,
                        trend_30d=trend_30d_df,
                        cpm_change_table=cpm_change_df
                    )
                    st.session_state['gemini_result'] = analysis_result
            
            if st.session_state['gemini_result']:
                st.markdown("### ğŸ“ AI è¨ºæ–·å ±å‘Š")
                st.markdown("---")
                st.markdown(st.session_state['gemini_result'])

        # ========== å´é‚Šæ¬„ï¼šä¸‹è¼‰ Excel ==========
        with st.sidebar:
            st.divider()
            excel_stack = []
            excel_stack.append(('Trend_Daily_30D', trend_30d_df))
            if cpm_change_df is not None and not cpm_change_df.empty:
                excel_stack.append(('CPM_Change_P7D_PP7D_P30D', cpm_change_df))
            excel_stack.extend(res_p1)
            excel_stack.extend(res_p7)
            excel_stack.extend(res_pp7)
            excel_stack.extend(res_p30)
            
            current_ai_result = st.session_state.get('gemini_result', None)
            
            excel_bytes = to_excel_single_sheet_stacked(excel_stack, AI_CONSULTANT_PROMPT, current_ai_result)
            
            if excel_bytes:
                button_label = "ğŸ“¥ ä¸‹è¼‰å®Œæ•´åˆ†æå ±è¡¨"
                if current_ai_result:
                    button_label += " (å·²åŒ…å« AI è¨ºæ–·)"
                
                st.download_button(
                    label=button_label,
                    data=excel_bytes,
                    file_name=f"Full_Report_{max_date.strftime('%Y%m%d')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.error("Excel ç”¢ç”Ÿå¤±æ•—ï¼Œè«‹æª¢æŸ¥ xlsxwriter å¥—ä»¶æ˜¯å¦å®‰è£ã€‚")

    except Exception as e:
        st.error(f"ç³»çµ±ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}")
        st.write("å»ºè­°æª¢æŸ¥ï¼š1. CSVæ ¼å¼æ˜¯å¦æ­£ç¢º 2. æ˜¯å¦åŒ…å«è½‰æ›/èŠ±è²»/æ›å…‰æ¬„ä½")
